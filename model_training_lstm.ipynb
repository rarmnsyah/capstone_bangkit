{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2f99678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6992605",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "data_path = os.path.join(cwd, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eead6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berita</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>['seru', 'uninstall', 'aplikasi', 'traveloka',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>['unwto', 'video', 'competition', 'region', 'e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>['wali', 'kota', 'makassar', 'mohammad', 'ramd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>['wakil', 'ketua', 'komisi', 'berantas', 'koru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>['aksi', 'walk', 'out', 'wo', 'pianis', 'anand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 berita  label\n",
       "946   ['seru', 'uninstall', 'aplikasi', 'traveloka',...      0\n",
       "175   ['unwto', 'video', 'competition', 'region', 'e...      0\n",
       "1825  ['wali', 'kota', 'makassar', 'mohammad', 'ramd...      0\n",
       "1155  ['wakil', 'ketua', 'komisi', 'berantas', 'koru...      1\n",
       "954   ['aksi', 'walk', 'out', 'wo', 'pianis', 'anand...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed = pd.read_csv(os.path.join(data_path, 'df_processed.csv'))\n",
    "df_processed = df_processed.drop(columns = [df_processed.columns[0]])\n",
    "df_processed.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc98972",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['berita'] = df_processed['berita'].apply(lambda x : eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91f406d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "berita    0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7001738d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2198,), (2198,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_processed['berita']\n",
    "y = df_processed['label']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f3455bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(cwd, 'model')\n",
    "# path = os.path.join(model_path, 'word2vec2.model')\n",
    "# model = gensim.models.word2vec.Word2Vec.load(path)\n",
    "\n",
    "# model.build_vocab(X, update=True)\n",
    "# model.train(X, total_examples=model.corpus_count, epochs=model.epochs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b059f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vectors = model.wv\n",
    "# word_vectors.save(os.path.join(model_path, \"word2vec.wordvectors\"))\n",
    "\n",
    "# Load back with memory-mapping = read-only, shared across processes.\n",
    "wv = KeyedVectors.load(os.path.join(model_path, \"word2vec.wordvectors\"), mmap='r')\n",
    "\n",
    "vector = wv['computer']  # Get numpy vector of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb77a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = vector.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19ecbb74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hillary', 0.6062372326850891),\n",
       " ('reagan', 0.5985161066055298),\n",
       " ('eisenhower', 0.596887469291687),\n",
       " ('rodham', 0.5639836192131042),\n",
       " ('nixon', 0.5635133981704712),\n",
       " ('kennedy', 0.5560458898544312),\n",
       " ('roosevelt', 0.5547446012496948),\n",
       " ('truman', 0.5528954267501831),\n",
       " ('sirleaf', 0.5269852876663208),\n",
       " ('barack', 0.5190994143486023)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"trump\",\"obama\", \"clinton\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a58f6716",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([ 1.72352290e+00, -1.83798993e+00, -1.35575926e+00,\n",
       "        -1.17041074e-01,  1.19458115e+00,  3.87547731e+00,\n",
       "        -6.80154502e-01,  2.02292943e+00,  4.39364552e-01,\n",
       "         5.76997995e-01,  3.44742656e+00,  5.74166119e-01,\n",
       "        -2.99447179e+00,  6.12090707e-01, -7.23787367e-01,\n",
       "        -7.22051740e-01, -2.90939093e-01,  1.51927543e+00,\n",
       "        -1.12848306e+00,  5.55331707e-01,  2.92788267e+00,\n",
       "         3.48406769e-02,  1.46782351e+00,  1.38434565e+00,\n",
       "        -8.39121342e-01, -1.01582602e-01, -1.66014278e+00,\n",
       "        -2.33312488e-01, -1.18575549e+00, -1.03784883e+00,\n",
       "         1.44607151e+00,  9.93070960e-01, -9.93266582e-01,\n",
       "         3.60394031e-01, -1.83221781e+00,  1.00411141e+00,\n",
       "        -5.24737120e-01,  3.35959125e+00,  8.98863912e-01,\n",
       "        -1.41647482e+00,  2.24933338e+00, -3.59520483e+00,\n",
       "        -1.82924604e+00, -8.92490029e-01,  2.98667169e+00,\n",
       "         4.46248621e-01, -2.25521445e+00,  1.08415782e+00,\n",
       "         5.84394217e-01,  3.31225008e-01,  6.11944735e-01,\n",
       "         2.93306994e+00,  3.17303610e+00,  7.88133204e-01,\n",
       "         1.70907342e+00,  8.52225542e-01,  1.33150256e+00,\n",
       "         9.39620197e-01,  2.72092319e+00, -1.94900766e-01,\n",
       "        -3.50402206e-01, -6.12591684e-01, -1.10582435e+00,\n",
       "        -2.71769792e-01, -7.03213587e-02, -9.42457318e-01,\n",
       "         7.78847635e-01,  2.06118298e+00, -4.94488776e-01,\n",
       "        -1.49633646e-01, -8.90280962e-01,  3.14565003e-01,\n",
       "        -1.74793959e-01,  1.02187407e+00, -2.06878591e+00,\n",
       "        -7.02193975e-01,  8.53852093e-01, -2.11102033e+00,\n",
       "        -6.67478383e-01, -2.79478765e+00, -4.47253078e-01,\n",
       "         9.14343953e-01, -1.45032418e+00, -4.27682728e-01,\n",
       "         1.83948241e-02, -2.75901985e+00,  3.27826023e+00,\n",
       "         2.01643872e+00, -4.97683018e-01, -3.02557945e-01,\n",
       "         1.46959439e-01,  2.17096424e+00,  2.49176383e+00,\n",
       "         1.05381034e-01, -6.95820093e-01, -4.06902105e-01,\n",
       "         1.49983525e+00, -1.02301645e+00,  5.17807543e-01,\n",
       "        -1.15501630e+00,  8.83128464e-01, -1.67285717e+00,\n",
       "        -1.64838231e+00,  1.22115529e+00, -3.82205546e-01,\n",
       "         1.62066489e-01, -2.75223589e+00, -6.21701539e-01,\n",
       "         1.54778314e+00,  4.65264291e-01, -2.74564385e+00,\n",
       "         9.81050491e-01, -1.98783123e+00, -1.32531309e+00,\n",
       "        -4.13558692e-01, -1.95936605e-01, -3.91509056e-01,\n",
       "        -8.64529312e-01,  1.41343176e-01, -2.19007596e-01,\n",
       "        -1.70675600e+00,  1.20304239e+00, -2.99562097e+00,\n",
       "        -9.08835292e-01, -1.92962575e+00,  2.13456288e-01,\n",
       "         1.64850175e+00,  1.75600588e+00, -8.68425846e-01,\n",
       "         7.03800321e-01,  9.62182164e-01, -2.75201797e-02,\n",
       "         1.83784032e+00,  1.67130673e+00,  7.71020770e-01,\n",
       "         1.13036335e+00, -1.44220555e+00, -7.69480467e-01,\n",
       "        -1.72586954e+00, -8.08237642e-02,  1.18672162e-01,\n",
       "         2.79572892e+00,  8.84456336e-01, -1.11678874e+00,\n",
       "         1.44582140e+00, -3.39996636e-01, -1.59504580e+00,\n",
       "         1.58003592e+00, -8.42274308e-01, -1.50691772e+00,\n",
       "        -3.36109209e+00,  1.45983303e+00, -5.19575834e-01,\n",
       "        -1.23793435e+00, -2.58600652e-01,  1.63017726e+00,\n",
       "         9.46752071e-01, -8.68170738e-01, -5.80512166e-01,\n",
       "         9.84426081e-01,  3.57522786e-01, -3.13426480e-02,\n",
       "         7.63960648e-04, -6.95278704e-01,  6.52962267e-01,\n",
       "        -2.13722944e-01, -8.90632272e-02,  7.98890531e-01,\n",
       "         4.69021350e-01, -3.09528738e-01,  1.91456564e-02,\n",
       "        -1.61575451e-01, -1.02622747e+00,  1.78595209e+00,\n",
       "        -8.21922243e-01, -5.89353144e-01, -3.64243872e-02,\n",
       "        -1.91753471e+00,  4.24262857e+00, -2.47214317e+00,\n",
       "        -2.36058503e-01,  3.41862440e+00, -1.40105987e+00,\n",
       "        -4.53612238e-01,  1.19575477e+00, -2.00371575e+00,\n",
       "         1.63432896e+00,  2.10607338e+00,  9.43451762e-01,\n",
       "        -9.57935274e-01, -2.52041101e-01, -1.46222305e+00,\n",
       "        -5.40340185e-01,  1.96875799e+00, -2.36424327e+00,\n",
       "         3.57654691e+00, -4.80195805e-02, -1.42886078e+00,\n",
       "        -6.29316196e-02, -1.91349912e+00, -1.89891434e+00,\n",
       "         1.23140836e+00,  2.02544015e-02,  3.98699045e-01,\n",
       "         2.87641168e+00, -2.02340558e-01, -1.13196361e+00,\n",
       "        -2.02281094e+00,  3.27201915e+00,  1.97352260e-01,\n",
       "         1.27873480e-01,  8.94828975e-01,  1.02949131e+00,\n",
       "        -4.43973958e-01, -2.54563165e+00, -4.85847592e-01,\n",
       "         1.26918197e+00, -5.02372265e-01,  5.23587726e-02,\n",
       "         1.11187361e-01, -6.62299693e-01, -8.17320049e-01,\n",
       "        -9.90259826e-01,  2.32538104e+00, -7.65719891e-01,\n",
       "         8.87723148e-01,  9.69425321e-01,  2.59098619e-01,\n",
       "        -1.18812725e-01, -1.18684657e-01, -2.08339977e+00,\n",
       "         1.99683651e-01,  3.77363205e+00, -1.03447759e+00,\n",
       "        -3.90899450e-01, -2.55893278e+00,  1.44399786e+00,\n",
       "        -3.10510683e+00, -1.88443851e+00,  7.20587432e-01,\n",
       "        -1.11856735e+00, -1.14534326e-01,  1.58651638e+00,\n",
       "         4.66912508e-01,  6.97600394e-02, -2.23034620e+00,\n",
       "         1.93492138e+00,  6.89810455e-01,  5.56436181e-01,\n",
       "         1.04333639e+00,  3.32754225e-01, -1.53673053e+00,\n",
       "        -2.71352440e-01,  1.96683323e+00, -2.26807475e+00,\n",
       "        -9.14844453e-01, -1.15187430e+00, -7.96907365e-01,\n",
       "         1.03402153e-01, -1.79238939e+00, -2.44378757e+00,\n",
       "        -6.72594905e-01, -1.09272861e+00,  1.67856777e+00,\n",
       "         1.65339255e+00, -2.54177928e-01,  8.19910645e-01,\n",
       "         1.66414642e+00, -5.74977100e-01,  3.43230271e+00,\n",
       "         5.56154549e-01,  1.17380917e+00, -6.68743372e-01,\n",
       "        -9.01473403e-01,  5.67579508e-01,  4.51540589e-01,\n",
       "         1.44066751e+00,  9.44583952e-01, -1.54060853e+00,\n",
       "        -2.92568374e+00, -3.60501766e-01,  2.38131955e-01,\n",
       "         1.47137487e+00,  6.38826251e-01,  8.06113064e-01,\n",
       "         2.45982385e+00, -1.95049953e+00,  5.73325083e-02,\n",
       "        -5.63935675e-02, -1.54450655e+00,  1.85293221e+00,\n",
       "        -1.92693189e-01,  7.62879789e-01,  3.33083004e-01,\n",
       "        -8.28337669e-02, -2.01886129e+00, -1.85701025e+00,\n",
       "        -1.12360251e+00, -5.32360226e-02,  2.08343267e-01], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "427d6b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332471"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c4d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_tokened = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd94ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sebut -> 1\n",
      "jadi -> 2\n",
      "kata -> 3\n",
      "laku -> 4\n",
      "orang -> 5\n",
      "tidak -> 6\n",
      "indonesia -> 7\n",
      "ada -> 8\n",
      "jelas -> 9\n",
      "media -> 10\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "for word, num in word_index.items():\n",
    "    print(f\"{word} -> {num}\")\n",
    "    if num == 10:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "459e6cec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in X_tokened], bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57af74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2198, 2162)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nos = np.array([len(x) for x in X_tokened])\n",
    "len(X_tokened), len(nos[nos  < 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98bc2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 1000 \n",
    "vocab_size = list(word_index.values())[-1] + 1\n",
    "\n",
    "#Making all news of size maxlen defined above\n",
    "X_tokened = pad_sequences(X_tokened, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "baff262d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,   621,   779,  1916,   223,\n",
       "         203,   454,  2210,     2,   326,  3405,  1744,   512,   109,\n",
       "         532,  5114,  4035,   239,  6528,   744,    47,  1510,   589,\n",
       "        2210,  7264,   979,   530, 16076,    38,    84,   154,  1094,\n",
       "         464,    78,  1696,  3406,   621,   779,  1377,   338, 11693,\n",
       "         498,  1330,   944,  1916,   404,   454,   326,  3405,   589,\n",
       "         512,   109,  4784,   744,   138,    47,  1510,   621,   779,\n",
       "          39,  1916,   101,   308,   141,    16,   356,   234,   310,\n",
       "        1917,  1026,  2309,  1893,  3692,  2499,     3,  1916,    32,\n",
       "        5495,   213,  2211, 16077,   530,   197,   197,   812,  1744,\n",
       "       16078,   512,   109,   504,   551,   621,   779,   154,  1745,\n",
       "        1971,   118,   126,   308,  7265,  4491,  1026,  2932,  3406,\n",
       "         365,   551,   621,   779,  1745,  1971,     2,   475,  1971,\n",
       "         264,   454,    88,  1401,   241,  1916,   621,   779,   656,\n",
       "         964,   125,   346,    41,  3038,   228,   965,   621,   779,\n",
       "        1330,   279,   318,   241,   633,   518,  7266,  6529,  5962,\n",
       "         162,  2580,   121,  2168,  9649,   633,   518,  7266,  6529,\n",
       "        5962,  4241, 16079,   437,   162,   633,     4,    97,   386,\n",
       "         153, 16080,   633,   162,   326,  3405,   118,   326,  3405,\n",
       "        3407,    64,   162,   232,   508,    64,  3407,    64,     3,\n",
       "         386,     3,  4241,   264,   454,    54,   162,   633,   658,\n",
       "         589,  2933,   621,   779,   162,   110,  4036,   633,   118,\n",
       "        1971,  2833,   899,  6530,   165,   193,   525,  2673,  1453,\n",
       "         241,   162,    88,   899,  1746,  1643, 16081,   489,  4242,\n",
       "        1360,  1226,  3860,   621,   779,   279,  1916,   685,   203,\n",
       "         118,   151,   551,   291,  2500,   621,   779,  1537,   493,\n",
       "         246,  1003,   499,   349,   107,    35,   536,   526,   147,\n",
       "        9650, 16082, 16083,  4785,  1330,   261,   634,   147,   861,\n",
       "         564,  1537,   551,  2500,  1026,   621,   779,   332,   195,\n",
       "           3,    35,   261,   311,  2834,  1239,  1401,   154,   270,\n",
       "          71,  1747,    51,  1026,  1916,   621,   779,   570,    71,\n",
       "        1401,   154,   270,    71,  6531,    51,   621,   779,   415,\n",
       "          89,  1916, 16084,  1147,  2310,   570,   397,   154,   314,\n",
       "          66,   147,    35,   147,    68,   551,   621,   779,   475,\n",
       "        1971,  4243, 16085,  3038,   228,     8,  2674,  1510,  4786,\n",
       "         621,   779,   191,   300, 16086,   204,  1330,   551,   475,\n",
       "           3,    58,    97,  1537,   551,   621,   779,  2210,   278,\n",
       "         404,   634,  1004,   315,   634,   508,   326,  3405,   138,\n",
       "        1744,  5114,  4035,   239,  3039,   589,  2933,  1264,    47,\n",
       "        1510,  4786,   530,   324,   547,   101,   308,   141,    16,\n",
       "         356,   234,   310,  1917,  1026,  2309,  1893,  3692,  2499,\n",
       "           3,  1916,   107,   502,   698,   395,  1916,   151,    54,\n",
       "         469,    58,   195,   680,     8,   822,   366,   395,  1916,\n",
       "           1,   965,    38,  1330,   900,   471,    30,    38,   502,\n",
       "        1330,  1495,  1916,     6,     8,  1402,    38,    46,    38,\n",
       "        4244,   233,   319,    71,    80,  1916,   813,   271,   621,\n",
       "         779,    66,  1893,   146,    48,    22,    93,  1475,   315,\n",
       "         634])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokened[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa4f5605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = list(vocab.values())[-1] + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        try:\n",
    "            weight_matrix[i] = model[word]\n",
    "        except:\n",
    "            weight_matrix[i] = np.zeros((EMBEDDING_DIM))\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "414a435e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([ 1.7787999 , -0.9378022 ,  1.0060095 ,  0.16896859,  3.1498325 ,\n",
       "        -3.715949  ,  2.030934  , -4.8869543 , -1.9737252 ,  2.173059  ,\n",
       "        -1.3982035 ,  2.0623238 , -3.3763707 ,  0.49902654,  3.628274  ,\n",
       "         3.744865  , -4.9337745 ,  3.867468  , -0.73850197,  0.86827576,\n",
       "        -2.1857445 ,  3.0824468 , -0.63157225,  2.8810287 , -1.8537045 ,\n",
       "         1.2335856 ,  1.0061756 , -2.7525938 , -1.2814913 , -0.68154544,\n",
       "         1.3148609 , -0.69788593, -2.1942852 , -0.94398767,  1.5720196 ,\n",
       "        -0.5822516 ,  3.5270689 ,  4.2941585 , -1.0492193 , -7.3668556 ,\n",
       "        -1.416308  , -1.3949232 , -2.8897524 , -1.5958921 ,  1.7353532 ,\n",
       "        -3.8356736 , -1.6109498 , -4.844603  ,  2.1372828 , -5.0528135 ,\n",
       "         0.6345121 , -2.8495333 , -2.1295373 ,  1.7329582 ,  2.9347038 ,\n",
       "        -1.3700193 ,  3.0358357 ,  0.37094435,  1.2258613 ,  0.92252296,\n",
       "         5.3010883 , -1.0828347 ,  5.1263523 , -2.361489  , -1.1889045 ,\n",
       "        -0.25904986, -3.3403466 ,  0.3232097 ,  1.1782033 , -0.670287  ,\n",
       "         0.6406182 , -4.996487  ,  0.55862015,  1.9532845 , -0.17366862,\n",
       "        -0.4546234 , -3.4230983 , -0.16722228, -3.474143  , -1.434517  ,\n",
       "         0.36463335, -3.8206124 ,  2.1732368 ,  1.8721058 ,  1.46368   ,\n",
       "        -3.0257158 , -1.8334627 ,  0.6605471 , -0.3242343 , -0.9987002 ,\n",
       "         0.11693144, -1.255845  , -0.726181  ,  1.3433554 ,  1.8599862 ,\n",
       "         1.6763672 , -2.4656    ,  1.6184593 ,  0.23825882,  0.30758125,\n",
       "        -1.0771037 , -2.3912902 ,  0.46196353, -1.0525702 , -0.8103921 ,\n",
       "         0.45454374,  3.383209  ,  5.386957  , -5.0639853 , -3.339759  ,\n",
       "         0.78997225, -5.3563437 ,  0.1456369 , -1.3275355 , -2.1133158 ,\n",
       "         1.4533212 ,  2.5020535 ,  0.43535677,  0.5399832 ,  2.2446299 ,\n",
       "         1.2422462 ,  0.83290243, -1.6870202 ,  0.8335931 ,  0.7194591 ,\n",
       "         2.7149138 , -0.23017506, -0.20933944, -2.1255176 , -2.223862  ,\n",
       "        -1.8332219 , -0.6277282 ,  2.501923  ,  2.2829974 , -3.807409  ,\n",
       "        -1.1392124 ,  0.07526996, -1.9090126 ,  2.764633  ,  2.5490403 ,\n",
       "         4.619119  ,  0.9286178 ,  4.09973   , -1.6005651 , -4.227822  ,\n",
       "         0.22601981,  0.9640539 , -0.48744446,  0.17868882, -0.43704057,\n",
       "         0.51147944, -2.374806  ,  5.0668545 ,  0.06419215,  1.3125004 ,\n",
       "        -1.3812431 ,  0.09946987,  0.7965496 ,  0.8585801 ,  0.43162757,\n",
       "        -0.496843  , -0.26306581, -0.3976378 , -1.1286603 ,  1.7004066 ,\n",
       "         0.45681816, -0.90645105, -2.4237978 , -1.9589975 , -2.161779  ,\n",
       "        -1.1292489 , -0.06071242,  0.54348594,  1.1709789 , -3.100572  ,\n",
       "         3.6962335 ,  0.31345475,  2.119341  ,  1.5817612 , -1.9707725 ,\n",
       "         1.2203294 ,  1.9245484 , -2.4219594 ,  2.6341634 , -6.0904336 ,\n",
       "         1.2389504 , -2.4207551 , -0.26386642, -1.4705418 ,  1.4575797 ,\n",
       "         0.71578556, -0.8058462 , -1.9659041 ,  2.4717832 ,  1.2261869 ,\n",
       "         2.5962331 ,  0.99560285, -1.4057772 ,  2.2173147 ,  2.6164398 ,\n",
       "         2.741828  ,  0.2814928 ,  0.27305743, -1.7890525 ,  0.33555526,\n",
       "         1.5915917 ,  3.1964269 , -1.4321661 ,  1.6261852 ,  0.22950599,\n",
       "         1.0654314 ,  1.0762545 ,  1.8238608 ,  0.02416975,  0.41938102,\n",
       "         1.2750582 , -2.4469724 ,  1.3093863 , -1.4341173 ,  3.5505052 ,\n",
       "         1.5428275 ,  0.62592125, -2.8028407 , -3.1365213 ,  3.9185636 ,\n",
       "        -0.2780772 , -0.578679  , -3.3239388 , -0.01098631,  0.71837556,\n",
       "         4.8650565 ,  1.5505985 , -3.9599578 , -0.32516402, -1.3758594 ,\n",
       "        -3.5349314 ,  2.1229053 ,  1.8949467 , -0.18973656, -0.7448556 ,\n",
       "        -0.92922634,  1.235319  ,  3.062877  , -2.9839644 , -3.4873116 ,\n",
       "        -3.5172987 , -0.4178262 ,  0.7838881 ,  5.543376  ,  1.7601553 ,\n",
       "        -0.6056388 , -0.9372244 , -2.0498464 , -0.31718114,  0.60589844,\n",
       "        -4.8605227 ,  2.220204  , -1.3290466 ,  0.15479685, -3.6488693 ,\n",
       "        -0.19484808,  1.0199066 ,  1.4092698 , -0.14115383,  4.610887  ,\n",
       "         1.0439843 ,  3.9702249 , -4.037712  ,  0.6683081 , -3.1273746 ,\n",
       "        -0.08001428, -1.1711912 ,  2.6159954 , -0.20476674,  4.171338  ,\n",
       "         1.6900363 ,  0.7886631 ,  4.472868  , -2.4764578 ,  0.33283132,\n",
       "         0.09874821,  4.402548  , -1.0994514 ,  4.9250684 , -0.0332567 ,\n",
       "         0.66373014, -1.0887341 ,  1.0389464 , -3.1477487 ,  0.17511034,\n",
       "        -0.94088155,  2.846674  , -1.1327615 , -2.152611  , -0.68319494,\n",
       "        -1.6704545 , -0.14822315,  1.9281676 , -0.6932414 ,  2.027123  ],\n",
       "       dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv['sebut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32c43531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sebut'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de421272",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vectors = get_weight_matrix(wv, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64c53568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.77879989, -0.9378022 ,  1.00600946,  0.16896859,  3.14983249,\n",
       "       -3.71594906,  2.0309341 , -4.88695431, -1.9737252 ,  2.17305899,\n",
       "       -1.39820349,  2.06232381, -3.37637067,  0.49902654,  3.62827396,\n",
       "        3.74486494, -4.93377447,  3.86746812, -0.73850197,  0.86827576,\n",
       "       -2.18574452,  3.08244681, -0.63157225,  2.88102865, -1.85370445,\n",
       "        1.2335856 ,  1.00617564, -2.75259376, -1.28149128, -0.68154544,\n",
       "        1.31486094, -0.69788593, -2.19428515, -0.94398767,  1.57201958,\n",
       "       -0.58225161,  3.52706885,  4.29415846, -1.04921925, -7.36685562,\n",
       "       -1.41630805, -1.39492321, -2.88975239, -1.59589207,  1.73535323,\n",
       "       -3.83567357, -1.61094975, -4.84460306,  2.13728285, -5.05281353,\n",
       "        0.63451213, -2.84953332, -2.12953734,  1.7329582 ,  2.93470383,\n",
       "       -1.37001932,  3.03583574,  0.37094435,  1.22586131,  0.92252296,\n",
       "        5.30108833, -1.08283472,  5.12635231, -2.36148906, -1.18890452,\n",
       "       -0.25904986, -3.34034657,  0.3232097 ,  1.17820334, -0.67028701,\n",
       "        0.64061821, -4.99648714,  0.55862015,  1.9532845 , -0.17366862,\n",
       "       -0.4546234 , -3.42309833, -0.16722228, -3.47414303, -1.43451703,\n",
       "        0.36463335, -3.82061243,  2.17323685,  1.87210584,  1.46368003,\n",
       "       -3.02571583, -1.83346272,  0.66054708, -0.32423431, -0.9987002 ,\n",
       "        0.11693144, -1.25584495, -0.72618097,  1.34335542,  1.85998619,\n",
       "        1.67636716, -2.46560001,  1.61845934,  0.23825882,  0.30758125,\n",
       "       -1.07710373, -2.39129019,  0.46196353, -1.05257022, -0.81039208,\n",
       "        0.45454374,  3.38320899,  5.38695717, -5.06398535, -3.33975911,\n",
       "        0.78997225, -5.35634375,  0.1456369 , -1.32753551, -2.11331582,\n",
       "        1.45332122,  2.5020535 ,  0.43535677,  0.53998321,  2.24462986,\n",
       "        1.24224615,  0.83290243, -1.68702018,  0.83359307,  0.71945912,\n",
       "        2.71491385, -0.23017506, -0.20933944, -2.12551761, -2.22386193,\n",
       "       -1.83322191, -0.62772822,  2.50192308,  2.28299737, -3.80740905,\n",
       "       -1.13921237,  0.07526996, -1.90901256,  2.76463294,  2.54904032,\n",
       "        4.61911917,  0.92861778,  4.09973001, -1.60056508, -4.22782183,\n",
       "        0.22601981,  0.96405393, -0.48744446,  0.17868882, -0.43704057,\n",
       "        0.51147944, -2.37480593,  5.06685448,  0.06419215,  1.31250036,\n",
       "       -1.38124311,  0.09946987,  0.79654962,  0.85858011,  0.43162757,\n",
       "       -0.49684301, -0.26306581, -0.39763781, -1.12866032,  1.70040655,\n",
       "        0.45681816, -0.90645105, -2.42379785, -1.95899749, -2.16177893,\n",
       "       -1.12924886, -0.06071242,  0.54348594,  1.1709789 , -3.10057211,\n",
       "        3.69623351,  0.31345475,  2.1193409 ,  1.58176124, -1.9707725 ,\n",
       "        1.2203294 ,  1.92454839, -2.4219594 ,  2.63416338, -6.0904336 ,\n",
       "        1.23895037, -2.42075515, -0.26386642, -1.47054183,  1.45757973,\n",
       "        0.71578556, -0.80584621, -1.96590412,  2.47178316,  1.22618687,\n",
       "        2.59623313,  0.99560285, -1.40577722,  2.21731472,  2.61643982,\n",
       "        2.74182796,  0.2814928 ,  0.27305743, -1.78905249,  0.33555526,\n",
       "        1.59159172,  3.19642687, -1.4321661 ,  1.62618518,  0.22950599,\n",
       "        1.06543136,  1.07625449,  1.82386076,  0.02416975,  0.41938102,\n",
       "        1.27505815, -2.44697237,  1.30938625, -1.43411732,  3.55050516,\n",
       "        1.54282749,  0.62592125, -2.80284071, -3.13652134,  3.9185636 ,\n",
       "       -0.27807719, -0.57867903, -3.32393885, -0.01098631,  0.71837556,\n",
       "        4.86505651,  1.5505985 , -3.95995784, -0.32516402, -1.37585938,\n",
       "       -3.53493142,  2.12290525,  1.89494669, -0.18973656, -0.74485558,\n",
       "       -0.92922634,  1.23531902,  3.06287694, -2.98396444, -3.4873116 ,\n",
       "       -3.5172987 , -0.41782621,  0.7838881 ,  5.54337597,  1.76015532,\n",
       "       -0.6056388 , -0.93722439, -2.04984641, -0.31718114,  0.60589844,\n",
       "       -4.86052275,  2.22020411, -1.32904661,  0.15479685, -3.64886928,\n",
       "       -0.19484808,  1.01990664,  1.40926981, -0.14115383,  4.61088705,\n",
       "        1.04398429,  3.97022486, -4.0377121 ,  0.66830808, -3.12737465,\n",
       "       -0.08001428, -1.17119122,  2.61599541, -0.20476674,  4.17133808,\n",
       "        1.6900363 ,  0.78866309,  4.47286797, -2.47645783,  0.33283132,\n",
       "        0.09874821,  4.40254784, -1.09945142,  4.92506838, -0.0332567 ,\n",
       "        0.66373014, -1.08873415,  1.03894639, -3.14774871,  0.17511034,\n",
       "       -0.94088155,  2.84667397, -1.13276148, -2.15261102, -0.68319494,\n",
       "       -1.6704545 , -0.14822315,  1.92816758, -0.69324142,  2.02712297])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99827e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Non-trainable embeddidng layer\n",
    "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n",
    "#LSTM \n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "del embedding_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62054d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 300)         8446500   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               219648    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8666277 (33.06 MB)\n",
      "Trainable params: 219777 (858.50 KB)\n",
      "Non-trainable params: 8446500 (32.22 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71c89d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tokened, y, test_size=0.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca7eea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      " 6/39 [===>..........................] - ETA: 1:03 - loss: 0.6645 - acc: 0.5781"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1908\\4032389786.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1781\u001b[0m                         ):\n\u001b[0;32m   1782\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1783\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1784\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1785\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m       return tracing_compilation.call_function(\n\u001b[0m\u001b[0;32m    868\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m       )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1262\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1263\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1264\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1265\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36mflat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;34m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0mflat_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[0;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mcall_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m       outputs = execute.execute(\n\u001b[0m\u001b[0;32m   1480\u001b[0m           \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     ]\n\u001b[1;32m---> 60\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.3, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2564e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (model.predict(X_test) >= 0.5).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a526a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
