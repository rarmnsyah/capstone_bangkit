{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{wilie2020indonlu,\n",
    "  title={IndoNLU: Benchmark and Resources for Evaluating Indonesian Natural Language Understanding},\n",
    "  author={Bryan Wilie and Karissa Vincentio and Genta Indra Winata and Samuel Cahyawijaya and X. Li and Zhi Yuan Lim and S. Soleman and R. Mahendra and Pascale Fung and Syafri Bahar and A. Purwarianti},\n",
    "  booktitle={Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing},\n",
    "  year={2020}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1726284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, TFAlbertModel, TFAutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.layers import Input, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fdb0449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    20944\n",
       "1     6474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "datapath = os.path.join(cwd, 'datasets')\n",
    "\n",
    "df = pd.read_excel(os.path.join(datapath, 'all_cleaned.xlsx'))\n",
    "df = df[['berita', 'label']]\n",
    "\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc225658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6474\n",
       "1    6474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['berita']]\n",
    "y = df['label']\n",
    "rus = RandomUnderSampler(random_state=1, replacement=True)# fit predictor and target variable\n",
    "X_new, y_new = rus.fit_resample(X,y)\n",
    "y_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbced1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>berita</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>psi sebut banding pecat viani limardi tolak ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12172</th>\n",
       "      <td>tawar koalisi gerindra pks bilang cari teman l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>dpr perintah kpu sepakat honor tugas tps naik ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17290</th>\n",
       "      <td>megawati sebut bicara koalisi capres lihat din...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10955</th>\n",
       "      <td>dana milu capai rp triliun jokowi minta detail...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27427</th>\n",
       "      <td>raja salman arab saudi bawa orang orang sudah ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27428</th>\n",
       "      <td>hehe selalu senyum lihat tingkah laku pak joko...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27429</th>\n",
       "      <td>pak jokowi jadi walikota periode pertama solo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27430</th>\n",
       "      <td>hari rabu nilai tukar rupiah puruk hingga semp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27431</th>\n",
       "      <td>kita tolak desember acara pastur monas majlis ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12948 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  berita  label\n",
       "235    psi sebut banding pecat viani limardi tolak ad...      0\n",
       "12172  tawar koalisi gerindra pks bilang cari teman l...      0\n",
       "5192   dpr perintah kpu sepakat honor tugas tps naik ...      0\n",
       "17290  megawati sebut bicara koalisi capres lihat din...      0\n",
       "10955  dana milu capai rp triliun jokowi minta detail...      0\n",
       "...                                                  ...    ...\n",
       "27427  raja salman arab saudi bawa orang orang sudah ...      1\n",
       "27428  hehe selalu senyum lihat tingkah laku pak joko...      1\n",
       "27429  pak jokowi jadi walikota periode pertama solo ...      1\n",
       "27430  hari rabu nilai tukar rupiah puruk hingga semp...      1\n",
       "27431  kita tolak desember acara pastur monas majlis ...      1\n",
       "\n",
       "[12948 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = X_new\n",
    "df_new['label'] = y_new\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a7f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "            \n",
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        super(Callback, self).__init__()\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "#         print(self.losses, self.val_losses)\n",
    "\n",
    "callback = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db4e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df_new, test_size=0.3, random_state=42,\n",
    "                                     stratify=df_new['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041b6307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'indobenchmark/indobert-lite-base-p1'\n",
    "# model_name = 'bert-base-cased'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 2)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = TFAutoModel.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.646"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(str(df_train.sample().berita.values).split()) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72de0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "\n",
    "X_train = tokenizer(\n",
    "    text=df_train['berita'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "X_test = tokenizer(\n",
    "    text=df_test['berita'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=max_len,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids=False,\n",
    "    return_attention_mask=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(70,), dtype=int32, numpy=\n",
       "array([    2, 14025, 12006,    46,  1495, 14149,  8221, 29842,   119,\n",
       "       16192, 14149,  2764,  4154,  6127,    19,  1225,  3892,  7043,\n",
       "        2441, 10242, 10639, 14025, 12006,    46,  1436,  8521,  3121,\n",
       "        1699,  1495, 14149,   745, 10354,  9674,  3976,  8221, 29842,\n",
       "       14025, 12006,    46,   304,  9418, 12085,  1241, 14149,  8445,\n",
       "        6776,  5115, 23296,   708, 18787, 21334,    63,  1800, 10165,\n",
       "       24871,  1904, 12291, 21603,    50,  6101,   216, 14149,  5115,\n",
       "         531,  5427,  9940,    63,   354,   728,     3])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.input_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7289dcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "# embeddings = dbert_model(input_ids, attention_mask = input_mask)[0]\n",
    "\n",
    "embeddings = model(input_ids, attention_mask = input_mask)[0] # 0 = last hidden state, 1 = poller_output\n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32, activation='relu')(out)\n",
    "\n",
    "y = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "# model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 70)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 70)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_albert_model (TFAlbertM  TFBaseModelOutputWithPooli   1168358   ['input_ids[0][0]',           \n",
      " odel)                       ng(last_hidden_state=(None   4          'attention_mask[0][0]']      \n",
      "                             , 70, 768),                                                          \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 768)                  0         ['tf_albert_model[0][0]']     \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  98432     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   4128      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    33        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11786177 (44.96 MB)\n",
      "Trainable params: 11786177 (44.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bb91911",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=5e-05, # HF recommendation\n",
    "    epsilon=1e-08,\n",
    "    clipnorm=1.0\n",
    ")\n",
    "\n",
    "loss = 'binary_crossentropy'\n",
    "metric = 'accuracy'\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metric\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c85bc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "567/567 [==============================] - 14469s 25s/step - loss: 0.1418 - accuracy: 0.9517 - val_loss: 0.1094 - val_accuracy: 0.9689\n",
      "Epoch 2/2\n",
      "567/567 [==============================] - 16319s 29s/step - loss: 0.0672 - accuracy: 0.9809 - val_loss: 0.0717 - val_accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = {'input_ids':X_train['input_ids'], 'attention_mask':X_train['attention_mask']},\n",
    "    y = df_train['label'],\n",
    "    validation_data = ({'input_ids':X_test['input_ids'], 'attention_mask':X_test['attention_mask']},\n",
    "                        df_test['label']),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('models/model_2023-11-29', custom_objects={\"TFAlbertModel\": TFAlbertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ce0f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 1919s 16s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1943\n",
      "           1       0.99      0.97      0.98      1942\n",
      "\n",
      "    accuracy                           0.98      3885\n",
      "   macro avg       0.98      0.98      0.98      3885\n",
      "weighted avg       0.98      0.98      0.98      3885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model.predict({'input_ids': X_test['input_ids'], 'attention_mask': X_test['attention_mask']})\n",
    "y_predicted = [1 if pred >= 0.5 else 0 for pred in predicted]\n",
    "print(classification_report(df_test['label'], y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8cb9770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-11-29'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3b870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model2023-11-29.keras'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'model{}.keras'.format(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "790e1c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir = 'model_{}'.format(str(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673c21fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_2023-11-29\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/model_2023-11-29\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/model_{}'.format(str(today)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\train_lite_indobert.ipynb Cell 23\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/train_lite_indobert.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m'\u001b[39m\u001b[39mmodels/model_2023-11-29\u001b[39m\u001b[39m'\u001b[39m, custom_objects\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mTFAlbertModel\u001b[39m\u001b[39m\"\u001b[39m: TFAlbertModel})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/model_2023-11-29', custom_objects={\"TFAlbertModel\": TFAlbertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 70)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 70)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_albert_model (TFAlbertM  TFBaseModelOutputWithPooli   1168358   ['input_ids[0][0]',           \n",
      " odel)                       ng(last_hidden_state=(None   4          'attention_mask[0][0]']      \n",
      "                             , 70, 768),                                                          \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 768)                  0         ['tf_albert_model[0][0]']     \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  98432     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   4128      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    33        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11786177 (44.96 MB)\n",
      "Trainable params: 11786177 (44.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmp9jypmrh7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmp9jypmrh7\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11481752"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "#saving converted model in \"converted_quant_model.tflite\" file\n",
    "open(\"models/converted_quant_model_litebert.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25489    1\n",
       "25646    1\n",
       "23126    1\n",
       "17712    0\n",
       "8492     0\n",
       "        ..\n",
       "23459    1\n",
       "4478     0\n",
       "17670    0\n",
       "24902    1\n",
       "23223    1\n",
       "Name: label, Length: 3885, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 70), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(X_test['attention_mask'][0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 70), dtype=int32, numpy=\n",
       "array([[    2,  9881,    55,  4425,  9319,  4007,  6101,  1871,   752,\n",
       "         6845, 18532, 12368,    63,  7498,   696,    66, 12291,  1225,\n",
       "         2600,   204,  2480,  1190, 20469,  9187,  2864,  3795,    39,\n",
       "        18303,  3248,  2193,  9305,  2855,   920,  1127,  2641,   441,\n",
       "          712,  5162,   491, 23089,  5129,  2336,  5115, 12368,    63,\n",
       "         7498,   696,    66,  1397,   752, 12291,  1225,  1269, 10834,\n",
       "         8259,  4849,  2600,   204,  4068, 20469,  9187,   683,  5115,\n",
       "         9319,  4007,   752,  6845,   629,   562,     3]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(X_test['input_ids'][0], input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04697829]] 0 1\n",
      "[[0.26599503]] 0 1\n",
      "[[0.0907713]] 0 1\n",
      "[[0.09970863]] 0 0\n",
      "[[0.02740857]] 0 0\n",
      "[[0.04011282]] 0 1\n",
      "[[0.05974764]] 0 1\n",
      "[[0.05749785]] 0 1\n",
      "[[0.10511776]] 0 1\n",
      "[[0.03395897]] 0 0\n",
      "[[0.03713262]] 0 1\n",
      "[[0.09178298]] 0 1\n",
      "[[0.04636384]] 0 1\n",
      "[[0.03091474]] 0 0\n",
      "[[0.06431253]] 0 0\n",
      "[[0.03103101]] 0 0\n",
      "[[0.05176967]] 0 0\n",
      "[[0.04576581]] 0 0\n",
      "[[0.09994493]] 0 1\n",
      "[[0.03856257]] 0 0\n",
      "[[0.10511776]] 0 1\n",
      "[[0.05621246]] 0 0\n",
      "[[0.05186893]] 0 1\n",
      "[[0.10495745]] 0 0\n",
      "[[0.10517703]] 0 0\n",
      "[[0.04555296]] 0 1\n",
      "[[0.04520574]] 0 1\n",
      "[[0.05428829]] 0 1\n",
      "[[0.05757875]] 0 1\n",
      "[[0.05540879]] 0 1\n",
      "[[0.03419619]] 0 1\n",
      "[[0.04439409]] 0 1\n",
      "[[0.03032523]] 0 1\n",
      "[[0.04132477]] 0 0\n",
      "[[0.07640906]] 0 0\n",
      "[[0.04397864]] 0 1\n",
      "[[0.09097861]] 0 1\n",
      "[[0.03391322]] 0 1\n",
      "[[0.10627519]] 0 1\n",
      "[[0.04618493]] 0 1\n",
      "[[0.10544624]] 0 0\n",
      "[[0.0410606]] 0 1\n",
      "[[0.10932309]] 0 1\n",
      "[[0.09970863]] 0 1\n",
      "[[0.05978647]] 0 0\n",
      "[[0.03033004]] 0 0\n",
      "[[0.04959667]] 0 0\n",
      "[[0.05582564]] 0 1\n",
      "[[0.03168443]] 0 0\n",
      "[[0.06143473]] 0 0\n",
      "[[0.04697829]] 0 0\n",
      "[[0.08356812]] 0 1\n",
      "[[0.13643566]] 0 0\n",
      "[[0.07959038]] 0 1\n",
      "[[0.02955767]] 0 0\n",
      "[[0.14775464]] 0 0\n",
      "[[0.05675441]] 0 0\n",
      "[[0.10633661]] 0 1\n",
      "[[0.07959038]] 0 1\n",
      "[[0.09230437]] 0 1\n",
      "[[0.09499326]] 0 1\n",
      "[[0.03364165]] 0 1\n",
      "[[0.03033004]] 0 1\n",
      "[[0.04045736]] 0 1\n",
      "[[0.03995005]] 0 0\n",
      "[[0.08584506]] 0 0\n",
      "[[0.0565373]] 0 0\n",
      "[[0.07511033]] 0 0\n",
      "[[0.07973937]] 0 1\n",
      "[[0.05111879]] 0 0\n",
      "[[0.07503971]] 0 1\n",
      "[[0.04377612]] 0 0\n",
      "[[0.07571068]] 0 1\n",
      "[[0.03364165]] 0 0\n",
      "[[0.04092915]] 0 0\n",
      "[[0.05655727]] 0 1\n",
      "[[0.09664335]] 0 1\n",
      "[[0.07452095]] 0 1\n",
      "[[0.07402249]] 0 1\n",
      "[[0.04161768]] 0 0\n",
      "[[0.07101803]] 0 1\n",
      "[[0.05268434]] 0 0\n",
      "[[0.05469475]] 0 0\n",
      "[[0.04107959]] 0 1\n",
      "[[0.04045736]] 0 0\n",
      "[[0.09193134]] 0 1\n",
      "[[0.04599277]] 0 0\n",
      "[[0.06641038]] 0 1\n",
      "[[0.05563258]] 0 0\n",
      "[[0.03168443]] 0 0\n",
      "[[0.10511776]] 0 0\n",
      "[[0.0745977]] 0 1\n",
      "[[0.04104661]] 0 0\n",
      "[[0.0852825]] 0 1\n",
      "[[0.03419619]] 0 0\n",
      "[[0.0740058]] 0 1\n",
      "[[0.02687126]] 0 0\n",
      "[[0.10084288]] 0 0\n",
      "[[0.1035317]] 0 0\n",
      "[[0.0740058]] 0 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.04697829]], dtype=float32),\n",
       " array([[0.26599503]], dtype=float32),\n",
       " array([[0.0907713]], dtype=float32),\n",
       " array([[0.09970863]], dtype=float32),\n",
       " array([[0.02740857]], dtype=float32),\n",
       " array([[0.04011282]], dtype=float32),\n",
       " array([[0.05974764]], dtype=float32),\n",
       " array([[0.05749785]], dtype=float32),\n",
       " array([[0.10511776]], dtype=float32),\n",
       " array([[0.03395897]], dtype=float32),\n",
       " array([[0.03713262]], dtype=float32),\n",
       " array([[0.09178298]], dtype=float32),\n",
       " array([[0.04636384]], dtype=float32),\n",
       " array([[0.03091474]], dtype=float32),\n",
       " array([[0.06431253]], dtype=float32),\n",
       " array([[0.03103101]], dtype=float32),\n",
       " array([[0.05176967]], dtype=float32),\n",
       " array([[0.04576581]], dtype=float32),\n",
       " array([[0.09994493]], dtype=float32),\n",
       " array([[0.03856257]], dtype=float32),\n",
       " array([[0.10511776]], dtype=float32),\n",
       " array([[0.05621246]], dtype=float32),\n",
       " array([[0.05186893]], dtype=float32),\n",
       " array([[0.10495745]], dtype=float32),\n",
       " array([[0.10517703]], dtype=float32),\n",
       " array([[0.04555296]], dtype=float32),\n",
       " array([[0.04520574]], dtype=float32),\n",
       " array([[0.05428829]], dtype=float32),\n",
       " array([[0.05757875]], dtype=float32),\n",
       " array([[0.05540879]], dtype=float32),\n",
       " array([[0.03419619]], dtype=float32),\n",
       " array([[0.04439409]], dtype=float32),\n",
       " array([[0.03032523]], dtype=float32),\n",
       " array([[0.04132477]], dtype=float32),\n",
       " array([[0.07640906]], dtype=float32),\n",
       " array([[0.04397864]], dtype=float32),\n",
       " array([[0.09097861]], dtype=float32),\n",
       " array([[0.03391322]], dtype=float32),\n",
       " array([[0.10627519]], dtype=float32),\n",
       " array([[0.04618493]], dtype=float32),\n",
       " array([[0.10544624]], dtype=float32),\n",
       " array([[0.0410606]], dtype=float32),\n",
       " array([[0.10932309]], dtype=float32),\n",
       " array([[0.09970863]], dtype=float32),\n",
       " array([[0.05978647]], dtype=float32),\n",
       " array([[0.03033004]], dtype=float32),\n",
       " array([[0.04959667]], dtype=float32),\n",
       " array([[0.05582564]], dtype=float32),\n",
       " array([[0.03168443]], dtype=float32),\n",
       " array([[0.06143473]], dtype=float32),\n",
       " array([[0.04697829]], dtype=float32),\n",
       " array([[0.08356812]], dtype=float32),\n",
       " array([[0.13643566]], dtype=float32),\n",
       " array([[0.07959038]], dtype=float32),\n",
       " array([[0.02955767]], dtype=float32),\n",
       " array([[0.14775464]], dtype=float32),\n",
       " array([[0.05675441]], dtype=float32),\n",
       " array([[0.10633661]], dtype=float32),\n",
       " array([[0.07959038]], dtype=float32),\n",
       " array([[0.09230437]], dtype=float32),\n",
       " array([[0.09499326]], dtype=float32),\n",
       " array([[0.03364165]], dtype=float32),\n",
       " array([[0.03033004]], dtype=float32),\n",
       " array([[0.04045736]], dtype=float32),\n",
       " array([[0.03995005]], dtype=float32),\n",
       " array([[0.08584506]], dtype=float32),\n",
       " array([[0.0565373]], dtype=float32),\n",
       " array([[0.07511033]], dtype=float32),\n",
       " array([[0.07973937]], dtype=float32),\n",
       " array([[0.05111879]], dtype=float32),\n",
       " array([[0.07503971]], dtype=float32),\n",
       " array([[0.04377612]], dtype=float32),\n",
       " array([[0.07571068]], dtype=float32),\n",
       " array([[0.03364165]], dtype=float32),\n",
       " array([[0.04092915]], dtype=float32),\n",
       " array([[0.05655727]], dtype=float32),\n",
       " array([[0.09664335]], dtype=float32),\n",
       " array([[0.07452095]], dtype=float32),\n",
       " array([[0.07402249]], dtype=float32),\n",
       " array([[0.04161768]], dtype=float32),\n",
       " array([[0.07101803]], dtype=float32),\n",
       " array([[0.05268434]], dtype=float32),\n",
       " array([[0.05469475]], dtype=float32),\n",
       " array([[0.04107959]], dtype=float32),\n",
       " array([[0.04045736]], dtype=float32),\n",
       " array([[0.09193134]], dtype=float32),\n",
       " array([[0.04599277]], dtype=float32),\n",
       " array([[0.06641038]], dtype=float32),\n",
       " array([[0.05563258]], dtype=float32),\n",
       " array([[0.03168443]], dtype=float32),\n",
       " array([[0.10511776]], dtype=float32),\n",
       " array([[0.0745977]], dtype=float32),\n",
       " array([[0.04104661]], dtype=float32),\n",
       " array([[0.0852825]], dtype=float32),\n",
       " array([[0.03419619]], dtype=float32),\n",
       " array([[0.0740058]], dtype=float32),\n",
       " array([[0.02687126]], dtype=float32),\n",
       " array([[0.10084288]], dtype=float32),\n",
       " array([[0.1035317]], dtype=float32),\n",
       " array([[0.0740058]], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='models/converted_quant_model_litebert.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "\n",
    "output_data = []\n",
    "pred = []\n",
    "\n",
    "for i in range(100):\n",
    "    input_data = tf.expand_dims(X_test['input_ids'][i], axis = 0)\n",
    "    input_intent = tf.expand_dims(X_test['attention_mask'][i], axis = 0)\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.set_tensor(input_details[1]['index'], input_intent)\n",
    "    interpreter.invoke()\n",
    "    get_tensor = interpreter.get_tensor(output_details[0]['index'])\n",
    "    print(get_tensor, 1 if get_tensor >= 0.5 else 0, df_test.label.values[i])\n",
    "    output_data.append(get_tensor)\n",
    "    pred.append(1 if get_tensor >= 0.5 else 0)\n",
    "\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pred).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
