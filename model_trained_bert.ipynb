{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f87d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertModel, BertConfig, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e28a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "datapath = os.path.join(cwd, 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0e8c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>berita</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>gunung agung erupsi pertama kali november letu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>jakarta cnn indonesia menteri bumn erick thohi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dosen fakultas dokter hewan ipb yusuf ridwan n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jakarta anggota tni serda n serda da tusuk ora...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aku tembak jatuh pesawat ukraina iran tuai gel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             berita  label\n",
       "0           0  gunung agung erupsi pertama kali november letu...      0\n",
       "1           1  jakarta cnn indonesia menteri bumn erick thohi...      0\n",
       "2           2  dosen fakultas dokter hewan ipb yusuf ridwan n...      0\n",
       "3           3  jakarta anggota tni serda n serda da tusuk ora...      0\n",
       "4           4  aku tembak jatuh pesawat ukraina iran tuai gel...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(datapath, 'df_processed.csv'))\n",
    "df['berita'] = df['berita'].apply(lambda x : \" \".join(eval(x)))\n",
    "# df['berita'] = df['berita'].apply(lambda x : eval(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6ecaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gunung agung erupsi pertama kali november letus jadi pukul wita asap tekan sedang warna kelabu tebal tinggi maksimum m atas puncak abu letus tiup lemah arah timurtenggara masyarakat minta tetap tenang selalu ikut rekomendasi pvmbg gunung agung letak kabupaten karangasem provinsi bal kembali erupsi sabtu november pukul wita abu tekan sedang setinggi m keluar atas puncak gunung agung rupa erupsi kepala pusat data informasi humas badan nasional tanggulang bencana bnpb sutopo purwo nugroho kata erupsi cara visual daerah culik batulompeh arah barat barat daya asap kelabukehitaman tekan sedang tutur status gunung agung tetap siaga level hingga kemudian pusat vulkanologi mitigasi bencana geologi pvmbg naik status gunung agung siaga level jadi awas level senin november jumlah ungsi akibat erupsi gunung agung capai jiwa asal wilayah masuk zona bahaya aktivitas gunung agung bal terus tingkat akibat bandara i gusti ngurah rai tutup communication and legal section bandara i gusti ngurah rai arie ahsanurrohim konfirmasi tutup bandara laku lama jam dasar notam bandara tutup pukul wita hingga pukul wita esok hari tutup mulai pagi hari esok hari kata jam kata arie senin november turut tutup bandara oleh abu vulkanik gunung agung tutup air space bandara hingga level imbas terbang domestik luar negeri ganggu tunda batal akibat tutup jumlah terbang alih darat bandarabandara dekat juanda makassar lombok kupang gunung agung terus erupsi ulang kali hingga akhir status tanggap darurat gunung agung cabut putus ambil rapat batas pimpin langsung presiden joko widodo jokowi wisma wedhapura sanur denpasar bal jumat desember jokowi papar alas cabut status darurat bencana gunung agung karena perlu kata presiden jumat malam kendati jamin ungsi tetap tangan baik halhal kait bencana erupsi gunung agung siap baik ungsi tetap tangan baik prosesproses kait gunung agung jika lihat erupsi stepstep manajemen evakuasi siap selamat tetap utama ujar jokowi presiden jokowi tegas status gunung agung awas level iv radius zona bahaya ada kilometer puncak kawah gunung agung jangan sampai diimagekan seluruh bal status awas kata tak lama cabut status gunung agung letus pada sabtu desember sore minggu desember pagi pukul wita keluar asap kelabu tebal tinggi kolom abu vulkanik meter atas puncak kawah arah timur laut kepala pusat data informasi humas badan nasional tanggulang bencana bnpb sutopo purwo nugroho kata erupsi langsung sekitar menit dua erupsi akhir turut dia tak perlu khawatir ada dampak rusak dua erupsi sebut aktivitas masyarakat bal normal justru banyak masyarakat sekitar bal nikmat erupsi tidak ada panik masyarakat ini masyarakat edukasi dengan cukup baik kena erupsi ancam dari gunung agung ujar sutopo terang tulis yang terima liputancom minggu desember'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['berita'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2f06aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2198,), (2198,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['berita']\n",
    "y = df['label']\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904896d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1758,), (440,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f0a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-large-p1', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "926bb2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(df['berita'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5a170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in df['berita']], bins=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ed05be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total berita 2198 || Berita terpanjang  22798  kata\n",
      "Total berita dengan <= 5 kata  0\n",
      "Total berita dengan > 1000 kata  1299\n"
     ]
    }
   ],
   "source": [
    "print('Total berita', len(df), '|| Berita terpanjang ', max([len(x) for x in df['berita']]), ' kata')\n",
    "print('Total berita dengan <= 5 kata ', sum([1 for x in df['berita'] if len(x) <= 5]))\n",
    "print('Total berita dengan > 1000 kata ', sum([1 for x in df['berita'] if len(x) > 1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ee7b80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_input_for_bert(news, max_len):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    i = 0\n",
    "    for new in news:\n",
    "        if (i < 3):\n",
    "            print(\"Berita\", new)\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            new,\n",
    "            add_special_tokens = True,\n",
    "            max_length = max_len,\n",
    "            pad_to_max_length = True,\n",
    "            return_attention_mask = True,\n",
    "        )\n",
    "        if (i < 3):\n",
    "            print('dict', encoded_dict['input_ids'])\n",
    "            \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    input_ids = tf.convert_to_tensor(input_ids)\n",
    "    attention_masks = tf.convert_to_tensor(attention_masks)\n",
    "    return input_ids, attention_masks\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e932c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berita orang reddit unggah foto ambil piala dunia minggu oleh fotografer ap frank augstein terang ap dapat temu shutterstock cukup mudah identifikasi orangorang foto bagai gemar tunggu tanding spanyol iran rusia reddit mata elang sama banyak orang lihat detail penting wanita foto id kena wanita kena jilbab foto ambil tanding tutup kepala bisa temu lengkap jelas referensi kategori klarifikasi sumber tanya salah satu anggota fafhh jelas ap singkat associated press about us the definitive source for news the associated press is an independent notforprofit news cooperative headquartered in new york city our teams in over countries tell the worlds stories from breaking news to investigative reporting we provide content and services to help engage audiences worldwide working with companies of all types from broadcasters to brands referensi yahoocom foto wanita iran tonton piala dunia hijab jadi viral meghan demaria gaya hidup yahoo juni foto gemar sepak bola iran piala dunia kazan rusia foto frank augstein ap rex shutterstock buah foto gemar tampak biasa piala dunia jadi viral lihat lebih dekat gambar tunjuk alas orang guna reddit unggah foto ambil piala dunia minggu oleh fotografer ap frank augstein terang ap dapat temu shutterstock cukup mudah identifikasi orangorang foto bagai gemar tunggu tanding spanyol iran rusia guna reddit mata elang sama banyak orang lihat detail penting wanita foto id kena wanita kena jilbab foto ambil tanding tutup kepala bisa temu piala dunia tahun adalah salah satu penting bagi wanita iran perempuan larang tonton giat olah raga pria sejak larang de fakto laku revolusi islam kata huffington post ada larang hukum resmi wanita tangkap hadir acara olahraga pria iran masa lalu pada hari rabu wanita gabung orang banyak stadion azadi teheran tonton siar langsung tanding iranspanyol memang bukan acara olahraga langsung ada negara tetapi adalah awal gemar seperti wanita dalam foto sekarangviral laku jalan rusia piala dunia lihat peristiwa piala dunia kazan wanita iran milik sempat hibur tim negara hidup tribun beberapa wanita bawa tandatanda sama piala dunia advokasi ubah dalam bijak iran dukung perempuan iran hadir stadion kata salah satu tanda piala dunia wanita dalam gambar belum identifikasi jelas dia mungkin pergi jilbab foto id orang reddit spekulasi mungkin jika foto ambil iran dia mungkin minta maka komentator tambah beberapa wanita tidak kena jilbab pergi luar iran itu bisa jilbab mungkin perlu negara karena atur tidak karena yakin agama komentar sebut jelas apa kondisi sekitar wanita dalam foto khusus seperti dia bersenangsenang bersoraksorai tim google translate chrome extension taut ke bahasa asli english sumber\n",
      "dict [2, 232, 3379, 14972, 4969, 21, 1072, 3422, 4353, 594, 1736, 213, 16277, 270, 11520, 6053, 23265, 4407, 270, 173, 14058, 16726, 12112, 1289, 2948, 724, 783, 9703, 1471, 1072, 12291, 12182, 4034, 28074, 5181, 8563, 5322, 3379, 14972, 1163, 17748, 500, 271, 232, 1173, 3460, 906, 922, 1072, 1519, 5381, 922, 5381, 5402, 1072, 3422, 28074, 4827, 1179, 166, 14058, 1556, 1127, 3832, 2573, 19020, 1099, 3001, 427, 282, 1225, 3441, 30375, 5612, 1127, 270, 3450, 15783, 6548, 8821, 9148, 1044, 1002, 20718, 14383, 11492, 1548, 4425, 1002, 15783, 6548, 8821, 374, 223, 23532, 3756, 8583, 22780, 47, 4425, 17984, 5624, 5674, 2369, 478, 6636, 30364, 48, 1713, 7305, 3949, 15008, 6593, 30362, 48, 5718, 10574, 12717, 30362, 612, 30366, 1002, 5671, 30362, 26394, 6706, 9881, 55, 4425, 1226, 13162, 51, 8358, 13783, 55, 4888, 1808, 831, 10961, 136, 13158, 1226, 15905, 3122, 2042, 5386, 17825, 5671, 24224, 26662, 4232, 3026, 28509, 30362, 1116, 2743, 6087, 30362, 6706, 29834, 853, 1226, 5733, 30362, 3832, 10980, 806, 1072, 922, 8563, 12443, 4353, 594, 8101, 472, 19946, 8097, 1937, 652, 5608, 2266, 669, 10980, 2193, 1072, 12182, 3396, 1522, 8563, 4353, 594, 24985, 5, 5322, 1072, 11520, 6053, 23265, 270, 520, 30388, 16726, 12112, 1289, 2948, 1307, 1072, 12182, 2735, 1167, 4353, 594, 472, 19946, 1173, 216, 920, 1153, 23450, 8705, 232, 3208, 3379, 14972, 4969, 21, 1072, 3422, 4353, 594, 1736, 213, 16277, 270, 11520, 6053, 23265, 4407, 270, 173, 14058, 16726, 12112, 1289, 2948, 724, 783, 9703, 1471, 1072, 12291, 12182, 4034, 28074, 5181, 8563, 5322, 3208, 3379, 14972, 1163, 17748, 500, 271, 232, 1173, 3460, 906, 922, 1072, 1519, 5381, 922, 5381, 5402, 1072, 3422, 28074, 4827, 1179, 166, 14058, 4353, 594, 262, 154, 427, 282, 906, 396, 922, 8563, 1747, 24634, 12443, 15572, 2052, 7160, 1380, 1098, 24634, 1595, 1050, 1289, 5427, 7010, 868, 661, 7925, 5868, 9813, 2162, 176, 24634, 885, 1983, 922, 12267, 2505, 1546, 2502, 1380, 8563, 890, 629, 126, 406, 3967, 922, 12198, 232, 271, 7857, 3741, 129, 3599, 1572, 12443, 15927, 30359, 728, 28074, 8563, 1868, 4983, 731, 531, 1546, 2502, 728, 176, 664, 638, 154, 1343, 12182, 295, 922, 112, 1072, 747, 16582, 20, 5427, 795, 5322, 4353, 594, 1173, 3224, 4353, 594, 24985, 5, 922, 8563, 2318, 2740, 4464, 58, 511, 664, 669, 13333, 388, 922, 4772, 7176, 500, 4353, 594, 21028, 7994, 112, 7051, 8563, 9162, 1747, 8563, 2505, 7857, 661, 427, 282, 2487, 4353, 594, 922, 112, 1153, 659, 9703, 1127, 364, 647, 1821, 5402, 1072, 1519, 232, 3379, 14972, 18635, 647, 338, 1072, 3422, 8563, 364, 647, 2757, 370, 12052, 1573, 3837, 388, 922, 119, 5381, 5402, 1821, 892, 8563, 137, 166, 5402, 647, 735, 664, 211, 7194, 119, 211, 2973, 1300, 2565, 5115, 1127, 387, 1186, 947, 922, 112, 1072, 857, 295, 364, 17781, 357, 11629, 7197, 94, 511, 2897, 21761, 16256, 13940, 25064, 2088, 30358, 43, 744, 2170, 8591, 1099, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Berita kepala humas bmkg hary tirto djatmiko kata hingga ada satu lembaga resmi pakar kredibel aku mampu prediksi gempa kategori klarifikasi sumber media sosial facebook narasi bencana biasa bukan nasional minta bantu apbd seluruh daerah nasional ayo turis mau nonton wisata gempa datang ntb kalau hutang terlalu besar takut rugi makin besar perintah cukup bohong rakyat jangan bohong dunia turut data status very high seismic risk sangat bahaya turis asing ntb saudara semua bukan stuntman jelas edar informasi media sosial tampil foto prediksi gempa beberapa negara salah satu indonesia serta ingat aktivitas seismik tinggi badan meteorologi klimatologi geofisika bmkg beri tanggap kait informasi sebut kepala humas bmkg hary tirto djatmiko kata informasi ini sudah edar sejak beberapa hari lalu foto edar tabel sisi kiri namanama negara sisi paling kanan upa prediksi gempa hary jelas kotak merah foto rupa informasi aktivitas gempa wilayah indonesia baik kecilkecil tengah maupun besar kata hary jumat hary kata hingga ini ada satu lembaga resmi pakar kredibel aku mampu prediksi gempa cerita gempa haicheng china kuat magnitudo februari rupa satusatunya peristiwa gempa di dunia sukses prediksi beberapa negara amerika serikat jepang prediksi gempa akan jadi hasil akurat hary tegas gempa prediksi akurat baik di mana waktu besar magnitudo hary imbau masyarakat bahwa informasi kait gempa terima asal sumbersumber kredibel resmi sebut lembaga alamat nomor kontak lembaga nama tugas hubung bahkan jelas metoda ilmiah data guna prediksi benar mereka tidak tanggung jawab ujar hary sebut penting informasi sebar dapat respons balik masyarakat lembaga keluar informasi dapat hubung minta jelas lebih lanjut ini banyak lembaga resmi sedia informasi gempa seperti bmkg usgs amerika serikat jma jepang gfz jerman emsc mediterania geoscope cea china lainlain papar referensi\n",
      "dict [2, 1179, 10092, 27598, 172, 30371, 4638, 1289, 4518, 29866, 3037, 661, 733, 176, 282, 2178, 1983, 6777, 11797, 22017, 304, 1085, 3801, 5767, 2573, 19020, 1099, 1313, 1258, 2861, 18275, 4680, 1167, 531, 1287, 2757, 1621, 9047, 969, 719, 1287, 4840, 12221, 422, 5888, 1223, 5767, 1095, 12329, 599, 8133, 1386, 421, 2790, 7571, 2855, 421, 3870, 724, 13169, 1829, 843, 13169, 594, 5295, 1006, 3448, 20076, 7460, 24561, 4229, 341, 15536, 310, 5275, 12221, 2945, 12329, 3650, 366, 531, 1911, 12006, 1049, 1127, 2168, 12, 683, 1313, 1258, 3228, 1072, 3801, 5767, 388, 664, 427, 282, 300, 501, 3100, 2310, 24561, 4229, 39, 717, 1269, 16409, 803, 19821, 3065, 803, 28637, 16951, 27598, 5030, 16192, 8445, 683, 5115, 1179, 10092, 27598, 172, 30371, 4638, 1289, 4518, 29866, 3037, 661, 683, 92, 259, 2168, 12, 1098, 388, 406, 629, 1072, 2168, 12, 4186, 2123, 3380, 8722, 664, 2123, 711, 2846, 912, 30354, 3801, 5767, 172, 30371, 1127, 3330, 1860, 1072, 6066, 683, 2310, 5767, 1350, 300, 342, 21438, 1172, 891, 421, 661, 172, 30371, 3253, 172, 30371, 661, 733, 92, 176, 282, 2178, 1983, 6777, 11797, 22017, 304, 1085, 3801, 5767, 1634, 5767, 5763, 10519, 30365, 4545, 1541, 25161, 3304, 6066, 4730, 3224, 5767, 26, 594, 2152, 3801, 388, 664, 1751, 2747, 1794, 3801, 5767, 150, 472, 562, 5485, 172, 30371, 5127, 5767, 3801, 5485, 342, 26, 1152, 486, 421, 25161, 172, 30371, 5881, 88, 552, 313, 683, 8445, 5767, 1788, 2158, 11498, 11797, 22017, 1983, 5115, 2178, 1953, 1288, 3865, 2178, 712, 1441, 23789, 816, 1127, 17235, 3869, 1006, 3208, 3801, 839, 267, 119, 3353, 1024, 3612, 172, 30371, 5115, 906, 683, 29912, 173, 9291, 2687, 552, 2178, 654, 683, 173, 23789, 2757, 1127, 216, 1727, 92, 271, 2178, 1983, 17176, 683, 5767, 295, 27598, 17647, 30362, 1751, 2747, 27965, 30354, 1794, 83, 30375, 30387, 3796, 822, 4688, 24175, 2695, 143, 1552, 3265, 13962, 30354, 4545, 4200, 15198, 3832, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Berita messi menang ballon dor\n",
      "dict [2, 12497, 2553, 12261, 46, 6859, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2606: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berita dokter sehat pakar sehat gizi nama inge permadhi sebut sengaja tel biji jambu biji cabai nyata masalah usus buntu banyak orang memang pikir keras macam biji masalah sehat picu rasa sakit luar biasa perut sebut padahal masalah usus buntu justru lebih sering kurang asupan air putih tiap hari lengkap jelas referensi kategori klarifikasi sumber tanya salah satu anggota fafhh post akun drynt trsnani sau facebookcomdryantisakun kali per tangkap layar buat narasi info sehat alam pribadi cegah lebih baik obat usus buntu bukan biji cabe biji jambu nyata justru kena usus buntu sering sepele lengkap bagi referensi jelas klikdokter tahu makan biji jambu usus buntu tahu mitos nih simak apa kata dr adithia kwee sini lengkap bagi referensi kompas bukan cabai jambu biji picu radang usus buntu lengkap bagi referensi dokter sehat pakar sehat gizi nama inge permadhi sebut sengaja tel biji jambu biji cabai nyata masalah usus buntu banyak orang memang pikir keras macam biji masalah sehat picu rasa sakit luar biasa perut sebut padahal masalah usus buntu justru lebih sering kurang asupan air putih tiap hari lengkap bagi referensi referensi klikdokter fakta mitos usus buntu dr adithia kwee jan wib shares tahu makan biji jambu usus buntu tahu mitos nih simak apa kata dr adithia kwee sini foto fakta mitos usus buntu klikdoktercom usus buntu umbai cacing buah organ bentuk rupa cacing rupa panjang sekum bagi usus besar panjang usus buntu biasa cm variasi hingga cm apendisitis radang usus buntu rupa buah prosses adang jadi lapis apendiks usus buntu sebar hingga area adang daerah rasa nyeri luar biasa mati lambat cari beberapa mitos sering dengar kena apendisitis misal mitos makan jambu biji cabai jadi radang usus buntu fakta salah orang rekan spesialis bedah lebih sering laku apendectomi operasi angkat usus buntu pernah temu butir biji jambu maupun biji cabai mitos lari makan usus buntu foto mules usus buntu fakta salah sama sekali hubung benar cara medis radang usus buntu jadi sumbat lumen usus sumbat jadi tingkat tekan lumen usus sumbat sekresi cair usus tumpuk manfaat bakteribakteri usus tumbuh subur bakteri mengaktifasi tahan tubuh lalu sel darah putih bentuk pus nanah buat tekan usus makin tinggi mitos usus buntu salah satu organ milik fungsi fakta salah prof loren g martin oklahoma state university usus buntu milik dwifungsi manusia manusia upa janin kandung ibu usia janin minggu apendiks ambil peran penting proses mekanisme kontrol biologis mana apendiks ambil kendali proses tahan mekanisme atur lingkung imbang dinamis cara konsisten mana martin teliti hasil bukti temu sel endokrin janin usia minggu ketika manusia usia dewasa tubuh manusia usia dewasa apendiks milik fungsi bagai organ limfatik teliti martin temu apendiks milik kandung sel limfoid indikasi kuat mungkin apendiks ambil peran mekanisme sistem imun manusia tahu dari sakit bahaya tentu sekarang pikir jadi makin buka bukan kompas bukan cabai jambu biji picu radang usus buntu dian maharani kompascom wib foto ilustrasi thinkstockcom jakarta kompascom terlalu banyak makan pedas sering sebut radang usus buntu biji cabai pula makan jambu biji banyak kasus radang usus buntu temu nyata bukan sering makan cabai maupun jambu biji dokter spesialis gizi klinik inge permadhi ungkap radang usus buntu justru bisa picu kurang minum tubuh kurang cair sebab usus buntu kalau periksa nyata bukan biji cabai masuk sering ada feses kotor hitam kering masuk usus buntu terang inge jakarta selasa inge jelas meski banyak makan serat tetapi kurang minum tetap tak bisa dorong sisa makan luar dari tubuh usus serat bentuk gumpal butuh cair kembang kemudian picu buang air besar konsumsi banyak serat tanpa asupan cair cukup justru bisa sebab kotor tumpuk akhir jadi sembelit buang air besar lancar sisa kotor tidak buang dari tubuh bisa jebak usus buntu lamakelamaan bisa keras halang akses usus buntu bisa picu adang usus buntu inge ingat penting penuh butuh cair tubuh dalam hari tidak konsumsi gelas air putih jaga hidrasi tubuh tulis dian maharani editor lusia kus anna dokter sehat tel biji jambu sebab usus buntu foto doktersehatcom buah mitos percaya bagi masyarakat indonesia mana tanpa sengaja tel biji dari jambu biji tidak akan bisa cerna perut akhir picu sakit usus buntu mitos benar ada pakar sehat gizi nama inge permadhi sebut bahwa tanpa sengaja tel biji jambu biji cabai nyata tidak akan sebab masalah usus buntu banyak orang memang pikir keras macam biji bisa sebab masalah sehat bisa picu rasa sakit luar biasa pada perut sebut padahal sebab dari masalah usus buntu justru lebih sering kurang asupan air putih tiap hari turut inge kita sudah konsumsi cukup banyak serat tiap hari tidak cukup butuh air putih tetap salur cerna akan sulit dorong sisa makan sudah selesai cerna alhasil serat dalam salur cerna akan gumpal tidak bisa segera keluar lewat buang air besar jika jumlah kotor sudah terlalu banyak tumpuk hingga capai usus buntu usus buntu akan alami adang kita sebut bagai sakit usus buntu lihat ada fakta inge saran kita untuk cukup butuh air minum seharihari sekitar gelas jaga sehat ginjal salur cerna untuk selalu konsumsi makan kadar gizi imbang rutin olahraga bisa tetap lancar buang air besar mampu cegah datang sakit usus buntu salin lengkap narasi guna sumber bagi info sehat alam pribadi cegah lebih baik dari pada obat usus buntu bukan biji cabe biji jambu akan tetapi nyata justru ini sebab bisa kena usus buntu sering sepele cerita orang usus buntu bukn kren mkn bijibijin kit seringkali diingtkn orng tu kit jngn teln biji jeruk nnti kena sakit usus buntu sy pernh diskusi dengn temn yng seorng dokter bedh dokter menerngkn bhw sudh ribun kli mengopersi orng yng ken skit usus buntu selm tangan opersi usus buntu belum pernh menemukn dlm usus buntu yng nmny biji jeruk biji jmbu biji cbe plgi yang nama biji durin dokter menerngkn pul bhw skit usus buntu terjdi kren kit kurng minum ir jadi sakit usus buntu itu dapat jadi bukn kren mkn bijibijin mudah itu kah y itu dapat jadi kren kurng minum ir dapat berkibt frekwensi bb jug berkurng frekwensi bb berkurng sementr mknn yng kit mkn sudh jdi smph yng sip bung mmpet usus besr khirny kotorn itu nik dn msuk usus buntu kren sudh berup kotorn busuk terjdilh infeksi infeksi dapat terjdi apabila kdr drh putih nik kren d infeksi mk klu d gejl usus buntu pada st check drh kdr leukosit psti nik dengn tjm jdi klu mu terhindr dri sakit usus buntu perbnyklh minum ir putih kotorn dlm usus buntu kn kelur flushing ir putih moga manfaat sumber\n",
      "dict [2, 1883, 1705, 6777, 1705, 4709, 712, 367, 30357, 655, 21072, 30356, 5115, 4380, 612, 5016, 12491, 5016, 10063, 3325, 805, 5952, 17080, 271, 232, 731, 3279, 2086, 1636, 5016, 805, 1705, 5415, 30360, 1214, 1252, 892, 1167, 3318, 5115, 2234, 805, 5952, 17080, 2814, 216, 884, 1057, 8671, 514, 1687, 2591, 406, 1556, 1127, 3832, 2573, 19020, 1099, 3001, 427, 282, 1225, 3441, 30375, 5612, 2162, 2641, 14459, 12006, 21565, 9926, 30356, 24825, 2861, 806, 3536, 19868, 8463, 23, 633, 62, 12267, 3665, 968, 18275, 1617, 1705, 668, 2028, 20180, 216, 342, 925, 5952, 17080, 531, 5016, 11661, 5016, 12491, 3325, 2814, 5381, 5952, 17080, 884, 15133, 1556, 396, 3832, 1127, 1730, 26262, 899, 521, 5016, 12491, 5952, 17080, 899, 9154, 2904, 5954, 387, 661, 1008, 14767, 2671, 30354, 5738, 2628, 1585, 1556, 396, 3832, 8030, 531, 10063, 12491, 5016, 5415, 30360, 9270, 5952, 17080, 1556, 396, 3832, 1883, 1705, 6777, 1705, 4709, 712, 367, 30357, 655, 21072, 30356, 5115, 4380, 612, 5016, 12491, 5016, 10063, 3325, 805, 5952, 17080, 271, 232, 731, 3279, 2086, 1636, 5016, 805, 1705, 5415, 30360, 1214, 1252, 892, 1167, 3318, 5115, 2234, 805, 5952, 17080, 2814, 216, 884, 1057, 8671, 514, 1687, 2591, 406, 1556, 396, 3832, 3832, 1730, 26262, 4014, 9154, 5952, 17080, 1008, 14767, 2671, 30354, 5738, 2628, 1726, 2230, 4731, 30362, 899, 521, 5016, 12491, 5952, 17080, 899, 9154, 2904, 5954, 387, 661, 1008, 14767, 2671, 30354, 5738, 2628, 1585, 1072, 4014, 9154, 5952, 17080, 1730, 26262, 806, 5952, 17080, 22371, 94, 9430, 1307, 1104, 902, 6066, 9430, 6066, 1422, 185, 67, 396, 5952, 421, 1422, 5952, 17080, 1167, 2825, 6182, 733, 2825, 24888, 5636, 10386, 37, 9270, 5952, 17080, 6066, 1307, 593, 1045, 176, 2692, 472, 11974, 24888, 5636, 2159, 5952, 17080, 29912, 733, 2828, 176, 2692, 719, 1214, 4558, 892, 1167, 1861, 5163, 2203, 388, 9154, 884, 5595, 5381, 24888, 5636, 10386, 37, 6346, 9154, 521, 12491, 5016, 10063, 472, 9270, 5952, 17080, 4014, 427, 232, 4571, 8861, 10489, 216, 884, 5427, 24888, 5636, 3260, 4878, 2394, 6845, 5952, 17080, 746, 14058, 7457, 5016, 12491, 891, 5016, 10063, 9154, 6185, 521, 5952, 17080, 1072, 431, 53, 5952, 17080, 4014, 427, 500, 684, 23789, 839, 354, 5049, 9270, 5952, 17080, 472, 20098, 30358, 3242, 9, 5952, 20098, 30358, 472, 1181, 2444, 3242, 9, 5952, 20098, 30358, 19724, 5785, 5952, 6848, 70, 1587, 3713, 17604, 1263, 5952, 2376, 7661, 3713, 10076, 91, 3423, 825, 629, 157, 1410, 1687, 902, 1009, 10387, 968, 2444, 5952, 2855, 717, 9154, 5952, 17080, 427, 282, 1104, 2318, 1539, 4014, 427, 1190, 17651, 83, 13218, 1151, 212, 2741, 12303, 6537, 5952, 17080, 2318, 11062, 8615, 666, 666, 912, 30354, 6376, 8210, 1066, 1816, 6376, 1736, 24888, 5636, 2159, 3422, 2693, 906, 699, 5921, 5926, 12557, 1152, 24888, 5636, 2159, 3422, 10579, 699, 3423, 5921, 7194, 1022, 76, 11907, 8459, 354, 6881, 1152, 13218, 8989, 562, 2873, 14058, 157, 27875, 9155, 6376, 1816, 1736, 640, 666, 1816, 2492, 825, 666, 1816, 2492, 24888, 5636, 2159, 2318, 1539, 12291, 1104, 22127, 4980, 8989, 13218, 14058, 24888, 5636, 2159, 2318, 8210, 157, 22127, 2830, 9420, 1541, 647, 24888, 5636, 2159, 3422, 2693, 5921, 737, 7725, 666, 899, 98, 1252, 5275, 1210, 747, 3279, 472, 2855, 3121, 531, 8030, 531, 10063, 12491, 5016, 5415, 30360, 9270, 5952, 17080, 5371, 15861, 720, 18329, 2230, 1072, 9672, 15139, 764, 2432, 806, 678, 18329, 1386, 271, 521, 9325, 884, 5115, 9270, 5952, 17080, 5016, 10063, 1355, 521, 12491, 5016, 271, 1578, 9270, 5952, 17080, 14058, 3325, 531, 884, 521, 10063, 891, 12491, 5016, 1883, 8861, 4709, 7810, 367, 30357, 655, 21072, 30356, 5396, 9270, 5952, 17080, 2814, 166, 5415, 30360, 1057, 2579, 825, 1057, 5785, 1440, 5952, 17080, 599, 8541, 3325, 531, 5016, 10063, 804, 884, 176, 21593, 4164, 2428, 3212, 804, 5952, 17080, 4407, 367, 30357, 678, 3943, 367, 30357, 1127, 2422, 271, 521, 5337, 638, 1057, 2579, 830, 368, 166, 14081, 5075, 521, 892, 98, 825, 5952, 5337, 902, 12985, 6818, 2655, 5785, 7917, 682, 5415, 30360, 5582, 514, 421, 3833, 271, 5337, 705, 8671, 5785, 724, 2814, 166, 1440, 4164, 6848, 70, 725, 472, 19085, 5582, 514, 421, 4843, 5075, 4164, 119, 5582, 98, 825, 166, 12075, 19, 5952, 17080, 27911, 166, 2086, 269, 16, 2268, 5952, 17080, 166, 5415, 30360, 176, 2692, 5952, 17080, 367, 30357, 3100, 906, 1876, 2655, 5785, 825, 112, 406, 119, 3833, 6387, 514, 1687, 7773, 7674, 91, 825, 1533, 5371, 15861, 720, 11000, 17639, 102, 4908, 14646, 1883, 1705, 612, 5016, 12491, 1440, 5952, 17080, 1072, 1883, 29974, 806, 1307, 9154, 2147, 396, 552, 300, 1152, 705, 4380, 612, 5016, 98, 12491, 5016, 119, 150, 166, 25285, 3318, 725, 5415, 30360, 1252, 5952, 17080, 9154, 839, 176, 6777, 1705, 4709, 712, 367, 30357, 655, 21072, 30356, 5115, 313, 705, 4380, 612, 5016, 12491, 5016, 10063, 3325, 119, 150, 1440, 805, 5952, 17080, 271, 232, 731, 3279, 2086, 1636, 5016, 166, 1440, 805, 1705, 166, 5415, 30360, 1214, 1252, 892, 1167, 126, 3318, 5115, 2234, 1440, 98, 805, 5952, 17080, 2814, 216, 884, 1057, 8671, 514, 1687, 2591, 406, 5295, 367, 30357, 219, 259, 3833, 724, 271, 5337, 2591, 406, 119, 724, 2655, 514, 1687, 830, 866, 58, 25285, 150, 1899, 14081, 5075, 521, 259, 2424, 25285, 13594, 5337, 112, 866, 58, 25285, 150, 12985, 6818, 119, 166, 1397, 654, 2145, 5582, 514, 421, 338, 991, 4164, 259, 1386, 271, 6848, 70, 733, 14510, 5952, 17080, 5952, 17080, 150, 1798, 176, 2692, 219, 5115, 12291, 1252, 5952, 17080, 1173, 176, 4014, 367, 30357, 3386, 219, 90, 724, 2655, 514, 2579, 3785, 947, 6387, 7773, 1705, 5012, 866, 58, 25285, 90, 811, 3833, 521, 4148, 4709, 11907, 3896, 2502, 166, 830, 4843, 5582, 514, 421, 1085, 20180, 1095, 1252, 5952, 17080, 22377, 1556, 18275, 3208, 1099, 396, 1617, 1705, 668, 2028, 20180, 216, 342, 98, 126, 925, 5952, 17080, 531, 5016, 11661, 5016, 12491, 150, 638, 3325, 2814, 92, 1440, 166, 5381, 5952, 17080, 884, 15133, 1634, 232, 5952, 17080, 729, 30355, 2652, 30355, 3]\n",
      "Berita sumber media sosial narasi jelas fakta pemberitahuan pihak jne situs resmi waspada hadap tipu mengatasnamakan jne january jakarta januari ref no mc mrdjnei yth langgan setia jne perihal waspada hadap tipu mengatasnamakan jne hormat hubung marak praktek tipu mengatasnamakan jne modus undi hadiah sama bahwa umum selenggara suatu program hadiah menang cara resmi selenggara jne akan umum lalu wwwjnecoid akun social media resmi facebook jne twitter jneid instagram jneid program hadiah selenggara cara resmi jne mungut biaya apa menang informasi atas nama seluruh manajemen jne kami menghimbau selalu berhatihati hadap praktek tipu mengatasnamakan jne informasi lebih lanjut sila hubung customer care jne telp email customercarejnecoid facebook jne twitter jneid instagram jneid hormat kami mayland hp head of marketing communication division pt jalur nugraha ekakurir\n",
      "dict [2, 1099, 1313, 1258, 18275, 1127, 4014, 7089, 1241, 9072, 1089, 1983, 8452, 26384, 17005, 22640, 9072, 8131, 678, 2826, 3328, 894, 8000, 4739, 30364, 25905, 30356, 20562, 19052, 5, 5416, 9072, 9424, 8452, 26384, 17005, 22640, 9072, 9674, 23789, 13800, 4576, 17005, 22640, 9072, 13815, 1603, 30356, 3750, 500, 313, 752, 157, 1005, 85, 607, 986, 3750, 2553, 354, 1983, 157, 1005, 85, 9072, 150, 752, 629, 3940, 25905, 3820, 2641, 6383, 1313, 1983, 2861, 9072, 4684, 9072, 64, 7484, 9072, 64, 986, 3750, 157, 1005, 85, 354, 1983, 9072, 11029, 63, 1162, 387, 2553, 683, 441, 712, 969, 2110, 9072, 321, 22702, 811, 9473, 26384, 4576, 17005, 22640, 9072, 683, 216, 1727, 15258, 23789, 6751, 7930, 9072, 6396, 1973, 6751, 19330, 25905, 3820, 2861, 9072, 4684, 9072, 64, 7484, 9072, 64, 9674, 321, 2481, 3367, 2109, 5674, 1116, 5899, 21221, 26909, 914, 2976, 25201, 13904, 19398, 72, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Berita stroke rupa sakit saraf paling sering akibat cacat mati samping duduk peringkat utama golong sakit saraf akibat mati stroke rupa salah satu tiga utama mati umum bagai fakta sebut tunjuk stroke rupa masalah utama bidang neurologi maupun sehat umum untik atas masalah krusial perlu strategi tanggulang stroke menbcakup aspek preventif terapi rahabilitasi promotif benar kasus stroke jadi sejak hal bukti pertama kasus stroke dasar obat tradisional cina teknik akupunktur teknik pernah lupa dampak timbul jadi makin besar bagaimana tahu orang serang stroke seluruh darah tubuh alir sangat kencang tuju buluh darah otak apabila giat beri terlambatsedikit buluh darah otak kuat tahan alir darah alir deras segera pecah sedikit sedikit pertama stroke cara keluar darah tiap ujung jari tangan ujung daun telinga satu cara baik beri pertama orang serang stroke cara selain selamat nyawa si derita timbul efek samping apa pertama ini jamin rupa gawat darurat dapat hasil hadap ini keluarga jangan panik tenang sipenderita tetap tempat mula mana jatuh mis kamar mandi kamar tidur mana jangan pindah pindah si derita tempat mula cepat pecah buluh darah halus otak derita bantu ambil posisi duduk baik jatuh saat keluar darah dapat laku baik jarum suntik apabila ada jarum jahit jarum pentul peniti dapat pakai lebih steril dulu cara bakar atas api segera jarum steril laku tusuk ujung jari tangan titik tusuk kirakira mm ujung kuku tiap jari cukup tusuk kali harap tiap jari keluar tetes darah keluar darah dapat bantu cara pencet apabila darah nyata tidak keluar ujung jari jangka waktu kirakira menit si derita akan segera sadar bila mulut sipenderita tampak mencong tidak normal dua daun telinga sipenderita harus ditariktarik sampai warna kemerahmerahan itu laku kali tusuk masingmasing ujung bawah daun telinga darah keluar banyak tetes tiap ujung daun telinga dengan demikian beberapa menit bentuk mulut sipenderita akan kembali normal ada sipenderita pulih dan tidak ada lain yang arti maka bawa sipenderita dengan hatihati dokter rumah sakit dekat dapat lebih lanjut\n",
      "dict [2, 8067, 6066, 1252, 6720, 711, 884, 1597, 8006, 1861, 2803, 2499, 4818, 1256, 1534, 225, 1252, 6720, 1597, 1861, 8067, 6066, 427, 282, 1224, 1256, 1861, 752, 12291, 4014, 5115, 23450, 8067, 6066, 805, 1256, 1254, 10752, 803, 891, 1705, 752, 4124, 39, 441, 805, 21157, 735, 2817, 25074, 16, 8067, 45, 13793, 4387, 2986, 23475, 4686, 1824, 12451, 4525, 473, 839, 1578, 8067, 472, 1098, 269, 2873, 736, 1578, 8067, 1205, 925, 2823, 4385, 1892, 12345, 27657, 1892, 746, 2516, 3345, 3344, 472, 2855, 421, 916, 899, 232, 9075, 8067, 969, 1410, 825, 2307, 30359, 310, 7993, 23641, 4816, 30369, 1410, 2965, 1496, 15572, 5030, 7038, 27692, 4816, 30369, 1410, 2965, 1541, 3423, 2307, 30359, 1410, 2307, 30359, 12575, 1397, 7155, 1160, 1160, 736, 8067, 354, 654, 1410, 2591, 3287, 3798, 1122, 3287, 2322, 5915, 282, 354, 342, 5030, 736, 232, 9075, 8067, 354, 751, 2368, 9619, 356, 14163, 3344, 1280, 2803, 387, 736, 92, 13553, 6066, 19328, 8491, 173, 562, 26384, 92, 1137, 843, 11777, 4134, 2885, 1592, 152, 830, 515, 7302, 1152, 2871, 846, 1073, 2952, 1073, 1559, 1152, 843, 5035, 5035, 356, 14163, 515, 7302, 972, 7155, 4816, 30369, 1410, 3695, 2965, 14163, 1621, 3422, 1602, 2499, 342, 2871, 305, 654, 1410, 173, 5427, 342, 9225, 15852, 1496, 176, 9225, 12683, 9225, 14369, 66, 20079, 30356, 173, 2468, 216, 14143, 1248, 354, 3456, 441, 2544, 1397, 9225, 14143, 5427, 18319, 3287, 3798, 1122, 2812, 18319, 6225, 3787, 3287, 10550, 2591, 3798, 724, 18319, 633, 6170, 2591, 3798, 654, 12789, 1410, 654, 1410, 173, 1621, 354, 926, 84, 1496, 1410, 3325, 119, 654, 3287, 3798, 3577, 486, 6225, 1815, 356, 14163, 150, 1397, 3645, 1063, 3240, 2885, 1592, 152, 2735, 311, 225, 119, 2966, 662, 2322, 5915, 2885, 1592, 152, 308, 8931, 3509, 493, 1321, 198, 580, 3305, 250, 137, 5427, 633, 18319, 1690, 3287, 1102, 2322, 5915, 1410, 654, 271, 12789, 2591, 3287, 2322, 5915, 79, 1143, 388, 1815, 902, 3240, 2885, 1592, 152, 150, 755, 2966, 176, 2885, 1592, 152, 14031, 41, 119, 176, 245, 34, 2561, 370, 4772, 2885, 1592, 152, 79, 6626, 1883, 448, 1252, 920, 173, 216, 1727, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "max_len = 1000\n",
    "X_train_inp, X_train_mask = mask_input_for_bert(X_train, max_len)\n",
    "X_test_inp, X_test_mask = mask_input_for_bert(X_test, max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18e525a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1758, 1000]), TensorShape([1758, 1000]), TensorShape([1758, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_label = np.expand_dims(y_train, axis=1)\n",
    "y_train_label = tf.convert_to_tensor(y_train_label)\n",
    "y_test_label = np.expand_dims(y_test, axis=1)\n",
    "y_test_label = tf.convert_to_tensor(y_test_label)\n",
    "\n",
    "X_train_inp.shape, X_train_mask.shape, y_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9d98d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-large-p1 and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertForSequenceClassification.from_pretrained('indobenchmark/indobert-large-p1', num_labels = 1)\n",
    "# bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1252b00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  335141888 \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 335142913 (1.25 GB)\n",
      "Trainable params: 335142913 (1.25 GB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Bert Model None\n"
     ]
    }
   ],
   "source": [
    "log_dir = cwd\n",
    "model_save_path = os.path.join(cwd, 'indobert_model.h5')\n",
    "\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
    "                                               save_weights_only = True,\n",
    "                                               monitor = 'val_loss',\n",
    "                                               mode = 'min',\n",
    "                                               save_best_only = True),\n",
    "            tf.keras.callbacks.TensorBoard(log_dir = log_dir)]\n",
    "print('\\nBert Model', bert_model.summary())\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "metric = tf.keras.metrics.BinaryAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=2e-5, epsilon=1e-08)\n",
    "\n",
    "bert_model.compile(loss=loss, optimizer=optimizer, metrics=[metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83663ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification/bert/embeddings/Gather_1 defined at (most recent call last):\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 418, in do_execute\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1716\\3648297071.py\", line 1, in <module>\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1638, in train_step\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1569, in call\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 780, in call\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 215, in call\n\nindices[0,945] = 945 is not in [0, 512)\n\t [[{{node tf_bert_for_sequence_classification/bert/embeddings/Gather_1}}]] [Op:__inference_train_function_45960]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1716\\3648297071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history=bert_model.fit([X_train_inp, X_train_mask],\n\u001b[0m\u001b[0;32m      2\u001b[0m                       \u001b[0my_train_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                       \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     ]\n\u001b[1;32m---> 60\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     61\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node tf_bert_for_sequence_classification/bert/embeddings/Gather_1 defined at (most recent call last):\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 418, in do_execute\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n\n  File \"C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_1716\\3648297071.py\", line 1, in <module>\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1638, in train_step\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1569, in call\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1557, in run_call_with_unpacked_inputs\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 780, in call\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\LENOVO\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 215, in call\n\nindices[0,945] = 945 is not in [0, 512)\n\t [[{{node tf_bert_for_sequence_classification/bert/embeddings/Gather_1}}]] [Op:__inference_train_function_45960]"
     ]
    }
   ],
   "source": [
    "history=bert_model.fit([X_train_inp, X_train_mask],\n",
    "                      y_train_label,\n",
    "                      batch_size = 32,\n",
    "                      epochs = 4,\n",
    "                      validation_data=([X_test_inp, X_test_mask], y_test_label),\n",
    "                      callbacks=callbacks),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd984b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
