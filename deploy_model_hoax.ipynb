{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "from transformers import TFAlbertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load('models/model_2023-11-29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['serving_default']\n"
     ]
    }
   ],
   "source": [
    "print(list(model.signatures.keys())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dense_2': TensorSpec(shape=(None, 1), dtype=tf.float32, name='dense_2')}\n"
     ]
    }
   ],
   "source": [
    "infer = model.signatures[\"serving_default\"]\n",
    "print(infer.structured_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling = infer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 70)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 70)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf_albert_model (TFAlbertM  TFBaseModelOutputWithPooli   1168358   ['input_ids[0][0]',           \n",
      " odel)                       ng(last_hidden_state=(None   4          'attention_mask[0][0]']      \n",
      "                             , 70, 768),                                                          \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " global_max_pooling1d (Glob  (None, 768)                  0         ['tf_albert_model[0][0]']     \n",
      " alMaxPooling1D)                                                                                  \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  98432     ['global_max_pooling1d[0][0]']\n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   4128      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    33        ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11786177 (44.96 MB)\n",
      "Trainable params: 11786177 (44.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('models/model_2023-11-29', custom_objects={\"TFAlbertModel\": TFAlbertModel})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(({'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}, None, None, None, None, None, None, None, None, True), {})\n\nSecond structure: type=tuple str=((TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask'), None, None, None, None, None, None, None, True), {})\n\nMore specifically: Substructure \"type=dict str={'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids')\" is not\nEntire first structure:\n(({'attention_mask': ., 'input_ids': ., 'token_type_ids': .}, ., ., ., ., ., ., ., ., .), {})\nEntire second structure:\n((., ., ., ., ., ., ., ., ., .), {})",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\deploy_model_hoax.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_tf_saved_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mmodels/model_2023-11-29\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m my_tf_saved_model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    231\u001b[0m         filepath,\n\u001b[0;32m    232\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    233\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    234\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    235\u001b[0m     )\n\u001b[0;32m    237\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    239\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39mcustom_objects, \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    240\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:524\u001b[0m, in \u001b[0;36m_tf_core_assert_same_structure\u001b[1;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[0;32m    522\u001b[0m str1 \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(_tf_core_map_structure(\u001b[39mlambda\u001b[39;00m _: _DOT, nest1))\n\u001b[0;32m    523\u001b[0m str2 \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(_tf_core_map_structure(\u001b[39mlambda\u001b[39;00m _: _DOT, nest2))\n\u001b[1;32m--> 524\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mEntire first structure:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mEntire second structure:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m     \u001b[39m%\u001b[39m (\u001b[39mstr\u001b[39m(e), str1, str2)\n\u001b[0;32m    527\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(({'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}, None, None, None, None, None, None, None, None, True), {})\n\nSecond structure: type=tuple str=((TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids'), TensorSpec(shape=(None, 70), dtype=tf.int32, name='attention_mask'), None, None, None, None, None, None, None, True), {})\n\nMore specifically: Substructure \"type=dict str={'attention_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'input_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name=None)}\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(None, 70), dtype=tf.int32, name='input_ids')\" is not\nEntire first structure:\n(({'attention_mask': ., 'input_ids': ., 'token_type_ids': .}, ., ., ., ., ., ., ., ., .), {})\nEntire second structure:\n((., ., ., ., ., ., ., ., ., .), {})"
     ]
    }
   ],
   "source": [
    "my_tf_saved_model = tf.keras.models.load_model(\n",
    "    'models/model_2023-11-29')\n",
    "my_tf_saved_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\transformers\\generation\\tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models/model_joblib.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'models/model_joblib.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\deploy_model_hoax.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m filePath \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodels/model_joblib.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(filePath, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trained_model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(file)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LENOVO/GitHub/capstone_bangkit/deploy_model_hoax.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trained_model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:648\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    646\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    647\u001b[0m     \u001b[39mwith\u001b[39;00m _read_fileobject(fobj, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[1;32m--> 648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1212\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1213\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1214\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\pickle.py:1589\u001b[0m, in \u001b[0;36m_Unpickler.load_reduce\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1587\u001b[0m args \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39mpop()\n\u001b[0;32m   1588\u001b[0m func \u001b[39m=\u001b[39m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m-> 1589\u001b[0m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\saving\\pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39mload_model(filepath, safe_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\saving\\pickle_utils.py:46\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     40\u001b[0m         f\u001b[39m.\u001b[39mwrite(serialized_model)\n\u001b[0;32m     41\u001b[0m     \u001b[39m# When loading, direct import will work for most custom objects\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[39m# though it will require get_config() to be implemented.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[39m# Some custom objects (e.g. an activation in a Dense layer,\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[39m# serialized as a string by Dense.get_config()) will require\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[39m# a custom_object_scope.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39;49mload_model(filepath, safe_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:275\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    272\u001b[0m             asset_store\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    274\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 275\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:240\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39mwith\u001b[39;00m ObjectSharingScope():\n\u001b[1;32m--> 240\u001b[0m     model \u001b[39m=\u001b[39m deserialize_keras_object(\n\u001b[0;32m    241\u001b[0m         config_dict, custom_objects, safe_mode\u001b[39m=\u001b[39;49msafe_mode\n\u001b[0;32m    242\u001b[0m     )\n\u001b[0;32m    244\u001b[0m all_filenames \u001b[39m=\u001b[39m zf\u001b[39m.\u001b[39mnamelist()\n\u001b[0;32m    245\u001b[0m \u001b[39mif\u001b[39;00m _VARS_FNAME \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m all_filenames:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[1;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m safe_mode_scope \u001b[39m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[0;32m    703\u001b[0m \u001b[39mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[1;32m--> 704\u001b[0m     instance \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(inner_config)\n\u001b[0;32m    705\u001b[0m     build_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mbuild_config\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    706\u001b[0m     \u001b[39mif\u001b[39;00m build_config:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3227\u001b[0m, in \u001b[0;36mModel.from_config\u001b[1;34m(cls, config, custom_objects)\u001b[0m\n\u001b[0;32m   3219\u001b[0m revivable_as_functional \u001b[39m=\u001b[39m (\n\u001b[0;32m   3220\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39min\u001b[39;00m {functional\u001b[39m.\u001b[39mFunctional, Model}\n\u001b[0;32m   3221\u001b[0m     \u001b[39mor\u001b[39;00m argspec\u001b[39m.\u001b[39margs[\u001b[39m1\u001b[39m:] \u001b[39m==\u001b[39m functional_init_args\n\u001b[0;32m   3222\u001b[0m     \u001b[39mor\u001b[39;00m (argspec\u001b[39m.\u001b[39mvarargs \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m argspec\u001b[39m.\u001b[39mvarkw \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mkwargs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3223\u001b[0m )\n\u001b[0;32m   3224\u001b[0m \u001b[39mif\u001b[39;00m is_functional_config \u001b[39mand\u001b[39;00m revivable_as_functional:\n\u001b[0;32m   3225\u001b[0m     \u001b[39m# Revive Functional model\u001b[39;00m\n\u001b[0;32m   3226\u001b[0m     \u001b[39m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[1;32m-> 3227\u001b[0m     inputs, outputs, layers \u001b[39m=\u001b[39m functional\u001b[39m.\u001b[39;49mreconstruct_from_config(\n\u001b[0;32m   3228\u001b[0m         config, custom_objects\n\u001b[0;32m   3229\u001b[0m     )\n\u001b[0;32m   3230\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m   3231\u001b[0m         inputs\u001b[39m=\u001b[39minputs, outputs\u001b[39m=\u001b[39moutputs, name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3232\u001b[0m     )\n\u001b[0;32m   3233\u001b[0m     functional\u001b[39m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py:1502\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[1;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[0;32m   1500\u001b[0m \u001b[39mwhile\u001b[39;00m layer_nodes:\n\u001b[0;32m   1501\u001b[0m     node_data \u001b[39m=\u001b[39m layer_nodes[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1502\u001b[0m     \u001b[39mif\u001b[39;00m process_node(layer, node_data):\n\u001b[0;32m   1503\u001b[0m         layer_nodes\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n\u001b[0;32m   1504\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1505\u001b[0m         \u001b[39m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m         \u001b[39m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\GitHub\\capstone_bangkit\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py:1442\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[1;34m(layer, node_data)\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1436\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(layer, \u001b[39m\"\u001b[39m\u001b[39m_preserve_input_structure_in_config\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1437\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m layer\u001b[39m.\u001b[39m_preserve_input_structure_in_config\n\u001b[0;32m   1438\u001b[0m ):\n\u001b[0;32m   1439\u001b[0m     input_tensors \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39munnest_if_single_tensor(\n\u001b[0;32m   1440\u001b[0m         input_tensors\n\u001b[0;32m   1441\u001b[0m     )\n\u001b[1;32m-> 1442\u001b[0m output_tensors \u001b[39m=\u001b[39m layer(input_tensors, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1444\u001b[0m \u001b[39m# Update node index map.\u001b[39;00m\n\u001b[0;32m   1445\u001b[0m output_index \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(output_tensors)[\n\u001b[0;32m   1446\u001b[0m     \u001b[39m0\u001b[39m\n\u001b[0;32m   1447\u001b[0m ]\u001b[39m.\u001b[39m_keras_history\u001b[39m.\u001b[39mnode_index\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "filePath = 'models/model_joblib.pkl'\n",
    "file = open(filePath, \"rb\")\n",
    "trained_model = joblib.load(file)\n",
    "trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='models/model_joblib.pkl'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
